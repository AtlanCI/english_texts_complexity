{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ain t</td>\n",
       "      <td>are not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aren t</td>\n",
       "      <td>are not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>are not / am notcan t</td>\n",
       "      <td>cannot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can t ve</td>\n",
       "      <td>cannot have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'cause</td>\n",
       "      <td>because</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   short         long\n",
       "0                  ain t      are not\n",
       "1                 aren t      are not\n",
       "2  are not / am notcan t       cannot\n",
       "3               can t ve  cannot have\n",
       "4                 'cause      because"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contr = pd.read_csv(\"contractions.csv\")\n",
    "contr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in zip(contr['short'],contr['long']):\n",
    "    contractions[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jimmy’s Breakfast</td>\n",
       "      <td>This is my friend Jimmy. He is from India. Jim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Girl from Green Valley</td>\n",
       "      <td>Green Valley was a small village near the Icy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice in Wonderland</td>\n",
       "      <td>Alice was beginning to get very tired of sitti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Volkswagen's emissions cheating will cost the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>My Friends</td>\n",
       "      <td>My name is Sonya. I am 20 and I come from Moro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     Title  \\\n",
       "0   1         Jimmy’s Breakfast   \n",
       "1   2  A Girl from Green Valley   \n",
       "2   3       Alice in Wonderland   \n",
       "3   4                Volkswagen   \n",
       "4   5                My Friends   \n",
       "\n",
       "                                                Text  \n",
       "0  This is my friend Jimmy. He is from India. Jim...  \n",
       "1  Green Valley was a small village near the Icy ...  \n",
       "2  Alice was beginning to get very tired of sitti...  \n",
       "3  Volkswagen's emissions cheating will cost the ...  \n",
       "4  My name is Sonya. I am 20 and I come from Moro...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = pd.read_excel(\"texts.xlsx\")\n",
    "texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basic_vocabulary = []\n",
    "with open(\"A1_vocab_processed.txt\", \"r\") as voc:\n",
    "    for word in voc.readlines():\n",
    "        basic_vocabulary.append(word[:-1])\n",
    "basic_vocabulary = set(basic_vocabulary)\n",
    "#basic_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And343', 'RB'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('...', ':'),\n",
       " ('received', 'VBD'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(\"And343 now for... received something completely different\")\n",
    "pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "receive\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"received\", pos = wordnet.VERB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(string.punctuation)\n",
    "s = string.punctuation + \"’\"\n",
    "#\"'\" in s\n",
    "\"’\"in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed element could not\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'will', 'go', 'could', 'not', 'have', 'many', 'woman']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_line = \"I will go couldn't had many women\"#’'\n",
    "exclude = string.punctuation + \"’\" +\"“\" + \"”\"#exclude ' for processing of such type of words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text_line (line, lemmatizer):\n",
    "    cleaned_line = ''\n",
    "    for word in line.split():\n",
    "        clean_word =''\n",
    "        for char in word:\n",
    "            if char not in exclude:\n",
    "                clean_word += char.lower()\n",
    "            else:\n",
    "                clean_word += ' '\n",
    "        \n",
    "        #cleaned_element = [''.join(ch for ch in el if ch not in exclude) for el in cleaned_element]        \n",
    "        #cleaned_element = [el.lower() for el in cleaned_element]\n",
    "        \n",
    "        #print(\"cleaned_word\",clean_word)\n",
    "        #cleaned_element = ''.join(cleaned_element)\n",
    "        if (clean_word in contractions):\n",
    "            clean_word = ''.join(contractions[clean_word])\n",
    "            print(\"parsed element\",clean_word)\n",
    "            \n",
    "        #cleaned_element = ''.join(cleaned_element)\n",
    "        #print(\"cleaned_element\",cleaned_element)\n",
    "        cleaned_line += clean_word + ' '\n",
    "    \n",
    "    #print(\"cleaned_line\", cleaned_line)\n",
    "    \n",
    "    #лемматизируем очищенные слова\n",
    "    text = word_tokenize(cleaned_line)\n",
    "    final_lemm_line = []\n",
    "    pos_text = pos_tag(text)\n",
    "    #print(pos_text)\n",
    "    for el in pos_text:\n",
    "        current_pos = get_wordnet_pos(el[1])\n",
    "        if(current_pos):\n",
    "            final_lemm_line.append(lemmatizer.lemmatize(el[0], pos = current_pos))\n",
    "            #print(el[0],\"pos = \", current_pos)\n",
    "        else:\n",
    "            final_lemm_line.append(lemmatizer.lemmatize(el[0]))\n",
    "            #print(\"no pos\", el[0])\n",
    "    #print(pos_tag(text))\n",
    "    \n",
    "    return final_lemm_line\n",
    "preprocess_text_line(test_line, lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is my friend Jimmy. He is from India. Jimmy is a vegetarian. The best breakfast for him is a glass of orange juice, two apples and three bananas. Jimmy  likes watermelons very much. A watermelon is green outside and red inside. It is hard and soft inside. It is juicy and sweet. What a lovely fruit!\\nA month ago Sally received a letter. It was an invitation for a wedding. Her sister Victoria is getting married. Last year Sally saw such a ceremony. It took place on Saturday. There were a lot of guests, people wore nice clothes, met a husband and a wife near the church, threw confetti, ate a very tasty cake, made videos and took photos.\\n\\nIn her letter Victoria asked Sally to be her bridesmaid. It means that on the day of wedding Sally must help Victoria when she puts her wedding dress on and brushes her hair. Sally must also accompany Victoria on her way to the church and carry a traditional bunch of flowers.\\nSally agreed with pleasure and bought a beautiful dress for the ceremony. It was white and green with a long nice silk skirt. But at home she understood that she couldn’t fit into it. What a pity!\\nThat is why Sally is on a diet now. She does not eat cakes, sweets and fried potatoes. She doesn’t even eat some very sweet fruit. She cooks vegetables, fish and boiled meat. She writes down everything she eats into a special notebook and adds up the calories. What is more, every morning she practices jogging and goes to the gym. She lost three kilos, but she wants to lose two kilos more. Everyone tells her she looks great, but she doesn’t agree. She is dreaming about a slice of wedding cake and does not want to give up. Dieting is not easy!\\n'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[\"Text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed element could not\n",
      "parsed element does not\n",
      "parsed element does not\n",
      "non_basic jimmy\n",
      "non_basic india\n",
      "non_basic jimmy\n",
      "non_basic vegetarian\n",
      "non_basic jimmy\n",
      "non_basic watermelon\n",
      "non_basic watermelon\n",
      "non_basic soft\n",
      "non_basic juicy\n",
      "non_basic lovely\n",
      "non_basic ago\n",
      "non_basic sally\n",
      "non_basic receive\n",
      "non_basic invitation\n",
      "non_basic wedding\n",
      "non_basic victoria\n",
      "non_basic marry\n",
      "non_basic sally\n",
      "non_basic saw\n",
      "non_basic such\n",
      "non_basic ceremony\n",
      "non_basic guest\n",
      "non_basic church\n",
      "non_basic throw\n",
      "non_basic confetti\n",
      "non_basic ate\n",
      "non_basic tasty\n",
      "non_basic video\n",
      "non_basic victoria\n",
      "non_basic sally\n",
      "non_basic bridesmaid\n",
      "non_basic mean\n",
      "non_basic wed\n",
      "non_basic sally\n",
      "non_basic must\n",
      "non_basic victoria\n",
      "non_basic wed\n",
      "non_basic brush\n",
      "non_basic sally\n",
      "non_basic must\n",
      "non_basic accompany\n",
      "non_basic victoria\n",
      "non_basic way\n",
      "non_basic church\n",
      "non_basic traditional\n",
      "non_basic bunch\n",
      "non_basic sally\n",
      "non_basic agree\n",
      "non_basic pleasure\n",
      "non_basic ceremony\n",
      "non_basic silk\n",
      "non_basic could\n",
      "non_basic fit\n",
      "non_basic pity\n",
      "non_basic sally\n",
      "non_basic diet\n",
      "non_basic fry\n",
      "non_basic even\n",
      "non_basic boil\n",
      "non_basic everything\n",
      "non_basic special\n",
      "non_basic notebook\n",
      "non_basic add\n",
      "non_basic calorie\n",
      "non_basic practice\n",
      "non_basic jog\n",
      "non_basic gym\n",
      "non_basic lose\n",
      "non_basic kilo\n",
      "non_basic lose\n",
      "non_basic kilo\n",
      "non_basic everyone\n",
      "non_basic agree\n",
      "non_basic dream\n",
      "non_basic slice\n",
      "non_basic wed\n",
      "non_basic diet\n",
      "237 77 0.32\n",
      "parsed element did not\n",
      "non_basic valley\n",
      "non_basic icy\n",
      "non_basic mountains\n",
      "non_basic mary\n",
      "non_basic happily\n",
      "non_basic grandmother\n",
      "non_basic grandma\n",
      "non_basic fell\n",
      "non_basic ill\n",
      "non_basic could\n",
      "non_basic anymore\n",
      "non_basic earn\n",
      "non_basic enough\n",
      "non_basic mary\n",
      "non_basic granny\n",
      "non_basic s\n",
      "non_basic mary\n",
      "non_basic s\n",
      "non_basic uncle\n",
      "non_basic rich\n",
      "non_basic circus\n",
      "non_basic mary\n",
      "non_basic surprise\n",
      "non_basic beloved\n",
      "non_basic grandmother\n",
      "non_basic circus\n",
      "non_basic granny\n",
      "non_basic already\n",
      "non_basic grown\n",
      "non_basic lady\n",
      "non_basic must\n",
      "non_basic everything\n",
      "non_basic practically\n",
      "non_basic high\n",
      "non_basic stone\n",
      "non_basic building\n",
      "non_basic friendly\n",
      "non_basic valley\n",
      "non_basic explain\n",
      "non_basic way\n",
      "non_basic circus\n",
      "non_basic turn\n",
      "non_basic follow\n",
      "non_basic wide\n",
      "non_basic turn\n",
      "non_basic left\n",
      "non_basic mary\n",
      "non_basic s\n",
      "non_basic uncle\n",
      "non_basic glad\n",
      "non_basic director\n",
      "non_basic circus\n",
      "non_basic care\n",
      "non_basic so\n",
      "non_basic mary\n",
      "non_basic s\n",
      "non_basic duty\n",
      "non_basic cage\n",
      "non_basic fee\n",
      "non_basic circus\n",
      "non_basic monkey\n",
      "non_basic elephant\n",
      "non_basic tiger\n",
      "non_basic lions\n",
      "non_basic mary\n",
      "non_basic complain\n",
      "non_basic granny\n",
      "non_basic stand\n",
      "non_basic curtain\n",
      "non_basic during\n",
      "non_basic performance\n",
      "non_basic dream\n",
      "non_basic stage…\n",
      "non_basic director\n",
      "non_basic king\n",
      "non_basic performance\n",
      "non_basic should\n",
      "non_basic act\n",
      "non_basic unfortunately\n",
      "non_basic most\n",
      "non_basic popular\n",
      "non_basic gymnast\n",
      "non_basic break\n",
      "non_basic else\n",
      "non_basic could\n",
      "non_basic instead\n",
      "non_basic suddenly\n",
      "non_basic mary\n",
      "non_basic program\n",
      "non_basic try\n",
      "non_basic uncle\n",
      "non_basic choice\n",
      "non_basic let\n",
      "non_basic performance\n",
      "non_basic mary\n",
      "non_basic even\n",
      "non_basic circus\n",
      "non_basic trick\n",
      "non_basic perfectly\n",
      "non_basic king\n",
      "non_basic applaud\n",
      "non_basic granny\n",
      "non_basic true\n",
      "305 103 0.34\n",
      "non_basic alice\n",
      "non_basic by\n",
      "non_basic nothing\n",
      "non_basic once\n",
      "non_basic twice\n",
      "non_basic peep\n",
      "non_basic thought\n",
      "non_basic alice\n",
      "non_basic without\n",
      "non_basic so\n",
      "non_basic consider\n",
      "non_basic own\n",
      "non_basic mind\n",
      "non_basic could\n",
      "non_basic sleepy\n",
      "non_basic stupid\n",
      "non_basic whether\n",
      "non_basic pleasure\n",
      "non_basic daisy\n",
      "non_basic chain\n",
      "non_basic worth\n",
      "non_basic trouble\n",
      "non_basic pick\n",
      "non_basic daisy\n",
      "non_basic suddenly\n",
      "non_basic rabbit\n",
      "non_basic pink\n",
      "non_basic by\n",
      "non_basic nothing\n",
      "non_basic so\n",
      "non_basic remarkable\n",
      "non_basic nor\n",
      "non_basic alice\n",
      "non_basic so\n",
      "non_basic way\n",
      "non_basic rabbit\n",
      "non_basic itself\n",
      "non_basic shall\n",
      "110 38 0.35\n",
      "non_basic volkswagen\n",
      "non_basic s\n",
      "non_basic emission\n",
      "non_basic cheat\n",
      "non_basic cost\n",
      "non_basic company\n",
      "non_basic least\n",
      "non_basic 15\n",
      "non_basic billion\n",
      "non_basic united\n",
      "non_basic state\n",
      "non_basic alone\n",
      "non_basic u\n",
      "non_basic s\n",
      "non_basic department\n",
      "non_basic justice\n",
      "non_basic announce\n",
      "non_basic volkswagen\n",
      "non_basic large\n",
      "non_basic ever\n",
      "non_basic automobile\n",
      "non_basic offer\n",
      "non_basic u\n",
      "non_basic s\n",
      "non_basic history\n",
      "non_basic report\n",
      "non_basic volkswagen\n",
      "non_basic cheat\n",
      "non_basic emission\n",
      "non_basic u\n",
      "non_basic s\n",
      "non_basic investigator\n",
      "non_basic german\n",
      "non_basic automaker\n",
      "non_basic instal\n",
      "non_basic software\n",
      "non_basic vehicle\n",
      "non_basic produce\n",
      "non_basic false\n",
      "non_basic result\n",
      "non_basic reduce\n",
      "non_basic pollution\n",
      "non_basic level\n",
      "non_basic during\n",
      "non_basic so\n",
      "non_basic vehicle\n",
      "non_basic wrongly\n",
      "non_basic pass\n",
      "non_basic u\n",
      "non_basic s\n",
      "non_basic pollution\n",
      "non_basic owner\n",
      "non_basic 500\n",
      "non_basic 000\n",
      "non_basic volkswagen\n",
      "non_basic automobile\n",
      "non_basic u\n",
      "non_basic s\n",
      "non_basic able\n",
      "non_basic sell\n",
      "non_basic vehicle\n",
      "non_basic company\n",
      "non_basic fair\n",
      "non_basic price\n",
      "non_basic owner\n",
      "non_basic 10\n",
      "non_basic 000\n",
      "66 67 1.02\n",
      "non_basic sonya\n",
      "non_basic 20\n",
      "non_basic morocco\n",
      "non_basic north\n",
      "non_basic africa\n",
      "non_basic history\n",
      "non_basic yuko\n",
      "non_basic japan\n",
      "non_basic japanese\n",
      "non_basic laura\n",
      "non_basic italy\n",
      "non_basic italian\n",
      "non_basic toby\n",
      "non_basic roby\n",
      "non_basic canada\n",
      "non_basic english\n",
      "non_basic french\n",
      "non_basic jimmy\n",
      "non_basic india\n",
      "non_basic hindi\n",
      "non_basic english\n",
      "non_basic map\n",
      "non_basic yuko\n",
      "non_basic jimmy\n",
      "non_basic laura\n",
      "non_basic toby\n",
      "non_basic roby\n",
      "81 27 0.33\n",
      "parsed element it is\n",
      "non_basic mom\n",
      "non_basic useful\n",
      "non_basic toby\n",
      "non_basic honey\n",
      "non_basic lemon\n",
      "non_basic laura\n",
      "non_basic headache\n",
      "non_basic advise\n",
      "non_basic loud\n",
      "non_basic yuko\n",
      "non_basic toothache\n",
      "non_basic don\n",
      "non_basic t\n",
      "non_basic roby\n",
      "non_basic lose\n",
      "non_basic weight\n",
      "non_basic advise\n",
      "non_basic so\n",
      "non_basic profession\n",
      "90 19 0.21\n",
      "parsed element it is\n",
      "non_basic toby\n",
      "non_basic roby\n",
      "non_basic canada\n",
      "non_basic t\n",
      "non_basic even\n",
      "non_basic laura\n",
      "non_basic italy\n",
      "non_basic sunny\n",
      "non_basic jimmy\n",
      "non_basic india\n",
      "non_basic heavy\n",
      "non_basic call\n",
      "non_basic tropical\n",
      "non_basic such\n",
      "non_basic sky\n",
      "non_basic cloud\n",
      "non_basic –\n",
      "non_basic dragon\n",
      "non_basic creature\n",
      "non_basic morocco\n",
      "non_basic rainbow\n",
      "112 21 0.19\n",
      "non_basic smith\n",
      "non_basic farmer\n",
      "non_basic forest\n",
      "non_basic sunny\n",
      "non_basic spot\n",
      "non_basic suddenly\n",
      "non_basic quickly\n",
      "non_basic forest\n",
      "non_basic smith\n",
      "non_basic follow\n",
      "non_basic puppy\n",
      "non_basic puppy\n",
      "non_basic alone\n",
      "non_basic puppy\n",
      "non_basic spot\n",
      "non_basic smith\n",
      "non_basic eats\n",
      "88 17 0.19\n",
      "parsed element I will\n",
      "parsed element does not\n",
      "parsed element was not\n",
      "parsed element I am\n",
      "parsed element will not\n",
      "parsed element I am\n",
      "non_basic matthew\n",
      "non_basic cuthbert\n",
      "non_basic suit\n",
      "non_basic proof\n",
      "non_basic avonlea\n",
      "non_basic matthew\n",
      "non_basic cuthbert\n",
      "non_basic I\n",
      "non_basic just\n",
      "non_basic step\n",
      "non_basic over\n",
      "non_basic gable\n",
      "non_basic marilla\n",
      "non_basic matthew\n",
      "non_basic s\n",
      "non_basic worthy\n",
      "non_basic finally\n",
      "non_basic conclude\n",
      "non_basic generally\n",
      "non_basic enough\n",
      "non_basic yet\n",
      "non_basic must\n",
      "non_basic happen\n",
      "non_basic since\n",
      "non_basic I\n",
      "non_basic puzzled\n",
      "non_basic s\n",
      "non_basic peace\n",
      "non_basic matthew\n",
      "non_basic cuthbert\n",
      "non_basic avonlea\n",
      "non_basic I\n",
      "non_basic marilla\n",
      "non_basic hope\n",
      "non_basic everything\n",
      "104 35 0.34\n",
      "parsed element it is\n",
      "non_basic center\n",
      "non_basic volleyball\n",
      "non_basic so\n",
      "non_basic bounce\n",
      "non_basic jump\n",
      "non_basic throw\n",
      "non_basic basket\n",
      "non_basic unfortunately\n",
      "non_basic playground\n",
      "non_basic busy\n",
      "non_basic must\n",
      "non_basic ben\n",
      "non_basic let\n",
      "non_basic s\n",
      "non_basic race\n",
      "non_basic square\n",
      "non_basic center\n",
      "non_basic ben\n",
      "non_basic alice\n",
      "non_basic alice\n",
      "non_basic win\n",
      "non_basic ben\n",
      "non_basic angry\n",
      "non_basic another\n",
      "non_basic race\n",
      "non_basic ben\n",
      "non_basic joe\n",
      "non_basic joe\n",
      "non_basic win\n",
      "non_basic ben\n",
      "non_basic hurt\n",
      "non_basic cry\n",
      "non_basic ben\n",
      "non_basic t\n",
      "non_basic karaoke\n",
      "non_basic song\n",
      "non_basic tasty\n",
      "non_basic so\n",
      "149 38 0.26\n",
      "non_basic ian\n",
      "non_basic lancaster\n",
      "non_basic fleming\n",
      "non_basic bear\n",
      "non_basic 28th\n",
      "non_basic 1908\n",
      "non_basic canterbury\n",
      "non_basic england\n",
      "non_basic journalist\n",
      "non_basic writer\n",
      "non_basic create\n",
      "non_basic most\n",
      "non_basic character\n",
      "non_basic twentieth\n",
      "non_basic century\n",
      "non_basic fiction\n",
      "non_basic james\n",
      "non_basic bond\n",
      "non_basic ian\n",
      "non_basic fleming\n",
      "non_basic educate\n",
      "non_basic eton\n",
      "non_basic eton\n",
      "non_basic soldier\n",
      "non_basic sandhurst\n",
      "non_basic military\n",
      "non_basic academy\n",
      "non_basic europe\n",
      "non_basic munich\n",
      "non_basic geneva\n",
      "non_basic fleming\n",
      "non_basic s\n",
      "non_basic journalist\n",
      "non_basic russia\n",
      "non_basic while\n",
      "non_basic news\n",
      "non_basic agency\n",
      "non_basic call\n",
      "non_basic reuters\n",
      "non_basic spy\n",
      "non_basic sell\n",
      "non_basic government\n",
      "non_basic secret\n",
      "non_basic fleming\n",
      "non_basic report\n",
      "non_basic spy\n",
      "non_basic special\n",
      "non_basic investigation\n",
      "non_basic reuters\n",
      "non_basic london\n",
      "non_basic return\n",
      "non_basic london\n",
      "non_basic banker\n",
      "85 53 0.62\n",
      "parsed element where is\n",
      "parsed element do not\n",
      "parsed element it is\n",
      "parsed element it is\n",
      "non_basic papa\n",
      "non_basic ax\n",
      "non_basic fern\n",
      "non_basic set\n",
      "non_basic hoghouse\n",
      "non_basic reply\n",
      "non_basic arable\n",
      "non_basic bear\n",
      "non_basic ax\n",
      "non_basic continue\n",
      "non_basic fern\n",
      "non_basic runt\n",
      "non_basic weak\n",
      "non_basic amount\n",
      "non_basic so\n",
      "non_basic decide\n",
      "non_basic away\n",
      "non_basic away\n",
      "non_basic shriek\n",
      "non_basic fern\n",
      "non_basic mean\n",
      "non_basic kill\n",
      "non_basic just\n",
      "non_basic others\n",
      "non_basic arable\n",
      "non_basic pitcher\n",
      "non_basic don\n",
      "non_basic t\n",
      "non_basic yell\n",
      "non_basic fern\n",
      "non_basic probably\n",
      "non_basic anyway\n",
      "non_basic fern\n",
      "non_basic push\n",
      "non_basic way\n",
      "non_basic outdoors\n",
      "non_basic wet\n",
      "non_basic earth\n",
      "non_basic smell\n",
      "non_basic springtime\n",
      "107 40 0.37\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "for text in texts[\"Text\"]:\n",
    "    processed_line = preprocess_text_line(text, lemmatizer)\n",
    "    processed_line_set = set(processed_line)\n",
    "    basic_words = []\n",
    "    out_of_bacis_words = []\n",
    "    for word in processed_line:\n",
    "        if word in basic_vocabulary:\n",
    "            #print(\"basic\", word)\n",
    "            basic_words.append(word)\n",
    "        else:\n",
    "            print(\"non_basic\",word)\n",
    "            out_of_bacis_words.append(word)\n",
    "    print(len(basic_words), len(out_of_bacis_words), round(len(out_of_bacis_words)/ len(basic_words), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
