{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. разделит на предложения, распарсить апострофы\n",
    "2. удалить точки в конце предложения\n",
    "\n",
    "анализировать грамматику, составлять карту грамматики для каждого текста. \n",
    "\n",
    "лемматизироват\n",
    "\n",
    "посчитать тфидф ко всему, применить веса ко всем словам текста (наверное составить словарь с весми а потом уже )\n",
    "\n",
    "пройтись по лемм тексту, смотреть в словарь допусктимого, в карту грамм свойств, а также на веса. рассчитывать итоговый вес допустимого и недопустимого\n",
    "цифры в допустимое и с максимальным штрафом\n",
    "\n",
    "задача сохранить грамматические свойства после лемматизации??!\n",
    "\n",
    "сделать карту грамматических свойств на нелемматизированном тексте, затем лемматизировать и сопоставить леммати текст с картой свйойств\n",
    "далее каждое слово проверять на предмет всей хурмы и соответственно относить в тот или иной словарь с тем или иным весом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ain t</td>\n",
       "      <td>are not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aren t</td>\n",
       "      <td>are not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can t</td>\n",
       "      <td>cannot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can t ve</td>\n",
       "      <td>cannot have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'cause</td>\n",
       "      <td>because</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      short         long\n",
       "0     ain t      are not\n",
       "1    aren t      are not\n",
       "2     can t       cannot\n",
       "3  can t ve  cannot have\n",
       "4    'cause      because"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contr = pd.read_csv(\"./materials/contractions.csv\")\n",
    "contr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {}\n",
    "for key, val in zip(contr['short'],contr['long']):\n",
    "    contractions[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660 50 81 196 196 3309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4296"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_vocabulary = []\n",
    "with open(\"./materials/A1_vocab_processed.txt\", \"r\") as voc:\n",
    "    for word in voc.readlines():\n",
    "        basic_vocabulary.append(word[:-1])\n",
    "#basic_vocabulary = set(basic_vocabulary)\n",
    "#basic_vocabulary\n",
    "\n",
    "adjectives = []\n",
    "with open(\"./materials/common_adj.txt\", \"r\") as common_adj:\n",
    "    for word in common_adj.readlines():\n",
    "        adjectives.append(word[:-1])\n",
    "        \n",
    "common_uncountable = []\n",
    "with open(\"./materials/common_unountable_manually_filtered.txt\", \"r\") as common_unctbl:\n",
    "    for word in common_unctbl.readlines():\n",
    "        common_uncountable.append(word[:-1])\n",
    "\n",
    "countries = []\n",
    "with open(\"./materials/countries.txt\", \"r\") as cntr:\n",
    "    for word in cntr.readlines():\n",
    "        countries.append(word[:-1])\n",
    "\n",
    "names = []\n",
    "with open(\"./materials/names.txt\", \"r\") as names_file:\n",
    "    for word in names_file.readlines():\n",
    "        names.append(word[:-1])\n",
    "        \n",
    "print(len(basic_vocabulary), len(adjectives), len(common_uncountable), len(countries), len(countries), len(names))\n",
    "final_basic_vocabulary = basic_vocabulary\n",
    "final_basic_vocabulary.extend(adjectives)\n",
    "final_basic_vocabulary.extend(common_uncountable)\n",
    "final_basic_vocabulary.extend(countries)\n",
    "final_basic_vocabulary.extend(names)\n",
    "len(final_basic_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jimmy’s Breakfast</td>\n",
       "      <td>This is my friend Jimmy. He is from India. Jim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Girl from Green Valley</td>\n",
       "      <td>Green Valley was a small village near the Icy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice in Wonderland</td>\n",
       "      <td>Alice was beginning to get very tired of sitti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Volkswagen's emissions cheating will cost the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>My Friends</td>\n",
       "      <td>My name is Sonya. I am 20 and I come from Moro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     Title  \\\n",
       "0   1         Jimmy’s Breakfast   \n",
       "1   2  A Girl from Green Valley   \n",
       "2   3       Alice in Wonderland   \n",
       "3   4                Volkswagen   \n",
       "4   5                My Friends   \n",
       "\n",
       "                                                Text  \n",
       "0  This is my friend Jimmy. He is from India. Jim...  \n",
       "1  Green Valley was a small village near the Icy ...  \n",
       "2  Alice was beginning to get very tired of sitti...  \n",
       "3  Volkswagen's emissions cheating will cost the ...  \n",
       "4  My name is Sonya. I am 20 and I come from Moro...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = pd.read_excel(\"./materials/texts.xlsx\")\n",
    "texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncuation_primary = string.punctuation + \"’\" +\"“\" + \"”\" \n",
    "puncuation_primary = puncuation_primary.replace(\".\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i cannot visit u.s. and i could not to go by your daddy s car',\n",
       " 'i want to say hello to her brother']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "test_line = \"I can't  visit U.S. and I couldn't   to go by your daddy's car. I want to say hello to her brother.\"#’'\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def punct_setnence_lower (line, sent_detector, debug = False, deep_debug = False):\n",
    "    initial_sentences_list = sent_detector.tokenize(line.strip())\n",
    "    final_sentences_list = []\n",
    "    \n",
    "    for sentence in initial_sentences_list:\n",
    "        if(debug): print(\"sentence:\", sentence)\n",
    "        cleaned_line = ''\n",
    "        #clean by word\n",
    "        for word in sentence.split():\n",
    "            if(debug): print(word)\n",
    "            clean_word =''\n",
    "            for char in word:\n",
    "                if(deep_debug): print(\"char before cleaning:\", char)\n",
    "                if char not in puncuation_primary:\n",
    "                    clean_word += char.lower()\n",
    "                    if(deep_debug): print(\"char after cleaning:\", char.lower())\n",
    "                else:\n",
    "                    clean_word += ' '\n",
    "                    if(deep_debug): print(\"char has been deleted\")\n",
    "            clean_word = clean_word.lstrip()\n",
    "            if(debug):print(\"non punctuation and lower:\",clean_word)       \n",
    "\n",
    "            if (clean_word in contractions):\n",
    "                if(debug):print(\"word before contractions parsing:\",clean_word)\n",
    "                clean_word = ''.join(contractions[clean_word])\n",
    "                if(debug):print(\"word after contractions parsing:\",clean_word)\n",
    "            if(debug): print(\"finally cleaned word/s:\",clean_word)    \n",
    "            cleaned_line += clean_word + ' '\n",
    "        #handle abbreviations delete dots only in the end    \n",
    "        for char_ind in range(len(cleaned_line) - 3, len(cleaned_line)):\n",
    "            max_dot_index = len(cleaned_line)\n",
    "            if cleaned_line[char_ind] == \".\":\n",
    "                if(char_ind < max_dot_index): max_dot_index = char_ind\n",
    "                break\n",
    "        cleaned_line = cleaned_line[:max_dot_index]    \n",
    "        cleaned_line = re.sub(' +', ' ', cleaned_line)\n",
    "        final_sentences_list.append(cleaned_line)\n",
    "    return final_sentences_list\n",
    "            \n",
    "clean_line = punct_setnence_lower(test_line, sent_detector,debug = False)\n",
    "clean_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_ex = punct_setnence_lower(texts[\"Text\"][0], sent_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is my friend jimmy',\n",
       " 'he is from india',\n",
       " 'jimmy is a vegetarian',\n",
       " 'the best breakfast for him is a glass of orange juice two apples and three bananas',\n",
       " 'jimmy likes watermelons very much',\n",
       " 'a watermelon is green outside and red inside',\n",
       " 'it is hard and soft inside',\n",
       " 'it is juicy and sweet',\n",
       " 'what a lovely fruit ',\n",
       " 'a month ago sally received a letter',\n",
       " 'it was an invitation for a wedding',\n",
       " 'her sister victoria is getting married',\n",
       " 'last year sally saw such a ceremony',\n",
       " 'it took place on saturday',\n",
       " 'there were a lot of guests people wore nice clothes met a husband and a wife near the church threw confetti ate a very tasty cake made videos and took photos',\n",
       " 'in her letter victoria asked sally to be her bridesmaid',\n",
       " 'it means that on the day of wedding sally must help victoria when she puts her wedding dress on and brushes her hair',\n",
       " 'sally must also accompany victoria on her way to the church and carry a traditional bunch of flowers',\n",
       " 'sally agreed with pleasure and bought a beautiful dress for the ceremony',\n",
       " 'it was white and green with a long nice silk skirt',\n",
       " 'but at home she understood that she could not fit into it',\n",
       " 'what a pity ',\n",
       " 'that is why sally is on a diet now',\n",
       " 'she does not eat cakes sweets and fried potatoes',\n",
       " 'she does not even eat some very sweet fruit',\n",
       " 'she cooks vegetables fish and boiled meat',\n",
       " 'she writes down everything she eats into a special notebook and adds up the calories',\n",
       " 'what is more every morning she practices jogging and goes to the gym',\n",
       " 'she lost three kilos but she wants to lose two kilos more',\n",
       " 'everyone tells her she looks great but she does not agree',\n",
       " 'she is dreaming about a slice of wedding cake and does not want to give up',\n",
       " 'dieting is not easy ']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this this DET DT nsubj {74: 89}\n",
      "is be VERB VBZ ROOT {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}\n",
      "my -PRON- ADJ PRP$ poss {74: 83, 'PronType': 'prs', 'Poss': 'yes'}\n",
      "friend friend NOUN NN attr {74: 91, 'Number': 'sing'}\n",
      "jimmy jimmy NOUN NN dep {74: 91, 'Number': 'sing'}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(processed_ex[0])\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          #token.shape_, token.is_alpha, token.is_stop,\n",
    "          nlp.vocab.morphology.tag_map[token.tag_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this this {74: 89}\n",
      "is be {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}\n",
      "my my {74: 83, 'PronType': 'prs', 'Poss': 'yes'}\n",
      "friends friend {74: 91, 'Number': 'plur'}\n",
      "jimmy jimmy {74: 91, 'Number': 'sing'}\n",
      "and and {74: 88, 'ConjType': 'coor'}\n",
      "catt catt {74: 91, 'Number': 'sing'}\n",
      "they they {74: 94, 'PronType': 'prs'}\n",
      "are be {74: 99, 'VerbForm': 'fin', 'Tense': 'pres'}\n",
      "swimmers swimmer {74: 91, 'Number': 'plur'}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"this is my friends jimmy and catt they are swimmers\")\n",
    "for token in doc:\n",
    "    if(token.lemma_[0] == \"-\"):\n",
    "        token.lemma_ = token.text\n",
    "    print(token.text, token.lemma_, nlp.vocab.morphology.tag_map[token.tag_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"this is my friends jimmy and catt they are swimmers\"\n",
    "spl = sent.split(\" \")\n",
    "len(doc) == len(spl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', {74: 89}),\n",
       " ('be',\n",
       "  {74: 99, 'Number': 'sing', 'Person': 3, 'Tense': 'pres', 'VerbForm': 'fin'}),\n",
       " ('my', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       " ('friend', {74: 91, 'Number': 'plur'}),\n",
       " ('jimmy', {74: 91, 'Number': 'sing'}),\n",
       " ('and', {74: 88, 'ConjType': 'coor'}),\n",
       " ('catt', {74: 91, 'Number': 'sing'}),\n",
       " ('they', {74: 94, 'PronType': 'prs'}),\n",
       " ('be', {74: 99, 'Tense': 'pres', 'VerbForm': 'fin'}),\n",
       " ('swimmer', {74: 91, 'Number': 'plur'})]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sent_gramm_features_map(sentence):\n",
    "    split_sent_list = sentence.split()\n",
    "    grammar_map = [None] * len(split_sent_list)  \n",
    "    parsed_sentence =  nlp(sentence)   \n",
    "    assert (len(parsed_sentence) == len(grammar_map))\n",
    "    for gramm_ind in range(len(split_sent_list)):\n",
    "        if(parsed_sentence[gramm_ind].lemma_[0] == \"-\"):\n",
    "            parsed_sentence[gramm_ind].lemma_ = parsed_sentence[gramm_ind].text\n",
    "        grammar_map[gramm_ind] = (parsed_sentence[gramm_ind].lemma_, nlp.vocab.morphology.tag_map[parsed_sentence[gramm_ind].tag_])\n",
    "        \n",
    "    return grammar_map\n",
    "\n",
    "get_sent_gramm_features_map(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('this', {74: 89}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('my', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('friend', {74: 91, 'Number': 'sing'}),\n",
       "  ('jimmy', {74: 91, 'Number': 'sing'})],\n",
       " [('he', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('from', {74: 84}),\n",
       "  ('india', {74: 91, 'Number': 'sing'})],\n",
       " [('jimmy', {74: 91, 'Number': 'sing'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('vegetarian', {74: 91, 'Number': 'sing'})],\n",
       " [('the', {74: 89}),\n",
       "  ('good', {74: 83, 'Degree': 'sup'}),\n",
       "  ('breakfast', {74: 91, 'Number': 'sing'}),\n",
       "  ('for', {74: 84}),\n",
       "  ('him', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('glass', {74: 91, 'Number': 'sing'}),\n",
       "  ('of', {74: 84}),\n",
       "  ('orange', {74: 83, 'Degree': 'pos'}),\n",
       "  ('juice', {74: 91, 'Number': 'sing'}),\n",
       "  ('two', {74: 92, 'NumType': 'card'}),\n",
       "  ('apple', {74: 91, 'Number': 'plur'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('three', {74: 92, 'NumType': 'card'}),\n",
       "  ('banana', {74: 91, 'Number': 'plur'})],\n",
       " [('jimmy', {74: 83, 'Degree': 'pos'}),\n",
       "  ('like',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('watermelon', {74: 91, 'Number': 'plur'}),\n",
       "  ('very', {74: 85, 'Degree': 'pos'}),\n",
       "  ('much', {74: 85, 'Degree': 'pos'})],\n",
       " [('a', {74: 89}),\n",
       "  ('watermelon', {74: 91, 'Number': 'sing'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('green', {74: 83, 'Degree': 'pos'}),\n",
       "  ('outside', {74: 85, 'Degree': 'pos'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('red', {74: 83, 'Degree': 'pos'}),\n",
       "  ('inside', {74: 91, 'Number': 'sing'})],\n",
       " [('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('hard', {74: 83, 'Degree': 'pos'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('soft', {74: 83, 'Degree': 'pos'}),\n",
       "  ('inside', {74: 84})],\n",
       " [('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('juicy', {74: 83, 'Degree': 'pos'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('sweet', {74: 83, 'Degree': 'pos'})],\n",
       " [('what', {74: 91, 'PronType': 'int|rel'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('lovely', {74: 83, 'Degree': 'pos'}),\n",
       "  ('fruit', {74: 91, 'Number': 'sing'})],\n",
       " [('a', {74: 89}),\n",
       "  ('month', {74: 91, 'Number': 'sing'}),\n",
       "  ('ago', {74: 85, 'Degree': 'pos'}),\n",
       "  ('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('receive', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('letter', {74: 91, 'Number': 'sing'})],\n",
       " [('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('an', {74: 89}),\n",
       "  ('invitation', {74: 91, 'Number': 'sing'}),\n",
       "  ('for', {74: 84}),\n",
       "  ('a', {74: 89}),\n",
       "  ('wedding', {74: 91, 'Number': 'sing'})],\n",
       " [('her', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('sister', {74: 91, 'Number': 'sing'}),\n",
       "  ('victoria', {74: 91, 'Number': 'sing'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('get', {74: 99, 'Aspect': 'prog', 'Tense': 'pres', 'VerbForm': 'part'}),\n",
       "  ('marry', {74: 99, 'Aspect': 'perf', 'Tense': 'past', 'VerbForm': 'part'})],\n",
       " [('last', {74: 83, 'Degree': 'pos'}),\n",
       "  ('year', {74: 91, 'Number': 'sing'}),\n",
       "  ('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('see', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('such', {74: 83, 'AdjType': 'pdt', 'PronType': 'prn'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('ceremony', {74: 91, 'Number': 'sing'})],\n",
       " [('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('take', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('place', {74: 91, 'Number': 'sing'}),\n",
       "  ('on', {74: 84}),\n",
       "  ('saturday', {74: 91, 'Number': 'sing'})],\n",
       " [('there', {74: 85, 'AdvType': 'ex'}),\n",
       "  ('be', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('lot', {74: 91, 'Number': 'sing'}),\n",
       "  ('of', {74: 84}),\n",
       "  ('guest', {74: 91, 'Number': 'plur'}),\n",
       "  ('people', {74: 91, 'Number': 'plur'}),\n",
       "  ('wear', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('nice', {74: 83, 'Degree': 'pos'}),\n",
       "  ('clothe', {74: 91, 'Number': 'plur'}),\n",
       "  ('meet', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('husband', {74: 91, 'Number': 'sing'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('wife', {74: 91, 'Number': 'sing'}),\n",
       "  ('near', {74: 84}),\n",
       "  ('the', {74: 89}),\n",
       "  ('church', {74: 91, 'Number': 'sing'}),\n",
       "  ('throw', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('confetti', {74: 91, 'Number': 'plur'}),\n",
       "  ('eat', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('very', {74: 85, 'Degree': 'pos'}),\n",
       "  ('tasty', {74: 83, 'Degree': 'pos'}),\n",
       "  ('cake', {74: 91, 'Number': 'sing'}),\n",
       "  ('make', {74: 99, 'Aspect': 'perf', 'Tense': 'past', 'VerbForm': 'part'}),\n",
       "  ('video', {74: 91, 'Number': 'plur'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('take', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('photo', {74: 91, 'Number': 'plur'})],\n",
       " [('in', {74: 84}),\n",
       "  ('her', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('letter', {74: 91, 'Number': 'sing'}),\n",
       "  ('victoria', {74: 91, 'Number': 'plur'}),\n",
       "  ('ask', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('to', {74: 93, 'PartType': 'inf', 'VerbForm': 'inf'}),\n",
       "  ('be', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('her', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('bridesmaid', {74: 91, 'Number': 'sing'})],\n",
       " [('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('mean',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('that', {74: 84}),\n",
       "  ('on', {74: 84}),\n",
       "  ('the', {74: 89}),\n",
       "  ('day', {74: 91, 'Number': 'sing'}),\n",
       "  ('of', {74: 84}),\n",
       "  ('wedding', {74: 91, 'Number': 'sing'}),\n",
       "  ('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('must', {74: 99, 'VerbType': 'mod'}),\n",
       "  ('help', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('victoria', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('when', {74: 85, 'PronType': 'int|rel'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('put',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('her', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('wedding', {74: 91, 'Number': 'sing'}),\n",
       "  ('dress', {74: 91, 'Number': 'sing'}),\n",
       "  ('on', {74: 84}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('brush',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('her', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('hair', {74: 91, 'Number': 'sing'})],\n",
       " [('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('must', {74: 99, 'VerbType': 'mod'}),\n",
       "  ('also', {74: 85, 'Degree': 'pos'}),\n",
       "  ('accompany', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('victoria', {74: 91, 'Number': 'plur'}),\n",
       "  ('on', {74: 84}),\n",
       "  ('her', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('way', {74: 91, 'Number': 'sing'}),\n",
       "  ('to', {74: 84}),\n",
       "  ('the', {74: 89}),\n",
       "  ('church', {74: 91, 'Number': 'sing'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('carry', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('traditional', {74: 83, 'Degree': 'pos'}),\n",
       "  ('bunch', {74: 91, 'Number': 'sing'}),\n",
       "  ('of', {74: 84}),\n",
       "  ('flower', {74: 91, 'Number': 'plur'})],\n",
       " [('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('agree', {74: 99, 'Aspect': 'perf', 'Tense': 'past', 'VerbForm': 'part'}),\n",
       "  ('with', {74: 84}),\n",
       "  ('pleasure', {74: 91, 'Number': 'sing'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('buy', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('beautiful', {74: 83, 'Degree': 'pos'}),\n",
       "  ('dress', {74: 91, 'Number': 'sing'}),\n",
       "  ('for', {74: 84}),\n",
       "  ('the', {74: 89}),\n",
       "  ('ceremony', {74: 91, 'Number': 'sing'})],\n",
       " [('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('white', {74: 83, 'Degree': 'pos'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('green', {74: 83, 'Degree': 'pos'}),\n",
       "  ('with', {74: 84}),\n",
       "  ('a', {74: 89}),\n",
       "  ('long', {74: 85, 'Degree': 'pos'}),\n",
       "  ('nice', {74: 83, 'Degree': 'pos'}),\n",
       "  ('silk', {74: 91, 'Number': 'sing'}),\n",
       "  ('skirt', {74: 91, 'Number': 'sing'})],\n",
       " [('but', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('at', {74: 84}),\n",
       "  ('home', {74: 91, 'Number': 'sing'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('understand', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('that', {74: 84}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('could', {74: 99, 'VerbType': 'mod'}),\n",
       "  ('not', {74: 85, 'Degree': 'pos'}),\n",
       "  ('fit', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('into', {74: 84}),\n",
       "  ('it', {74: 94, 'PronType': 'prs'})],\n",
       " [('what', {74: 91, 'PronType': 'int|rel'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('pity', {74: 91, 'Number': 'sing'})],\n",
       " [('that', {74: 89}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('why', {74: 85, 'PronType': 'int|rel'}),\n",
       "  ('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('on', {74: 84}),\n",
       "  ('a', {74: 89}),\n",
       "  ('diet', {74: 91, 'Number': 'sing'}),\n",
       "  ('now', {74: 85, 'Degree': 'pos'})],\n",
       " [('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('do',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('not', {74: 85, 'Degree': 'pos'}),\n",
       "  ('eat', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('cake', {74: 91, 'Number': 'plur'}),\n",
       "  ('sweet', {74: 91, 'Number': 'plur'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('fry', {74: 99, 'Aspect': 'perf', 'Tense': 'past', 'VerbForm': 'part'}),\n",
       "  ('potato', {74: 91, 'Number': 'plur'})],\n",
       " [('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('do',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('not', {74: 85, 'Degree': 'pos'}),\n",
       "  ('even', {74: 85, 'Degree': 'pos'}),\n",
       "  ('eat', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('some', {74: 89}),\n",
       "  ('very', {74: 85, 'Degree': 'pos'}),\n",
       "  ('sweet', {74: 83, 'Degree': 'pos'}),\n",
       "  ('fruit', {74: 91, 'Number': 'sing'})],\n",
       " [('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('cook',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('vegetable', {74: 91, 'Number': 'plur'}),\n",
       "  ('fish', {74: 99, 'Tense': 'pres', 'VerbForm': 'fin'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('boil', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('meat', {74: 91, 'Number': 'sing'})],\n",
       " [('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('write',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('down', {74: 84}),\n",
       "  ('everything', {74: 91, 'Number': 'sing'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('eat',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('into', {74: 84}),\n",
       "  ('a', {74: 89}),\n",
       "  ('special', {74: 83, 'Degree': 'pos'}),\n",
       "  ('notebook', {74: 91, 'Number': 'sing'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('add',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('up', {74: 93}),\n",
       "  ('the', {74: 89}),\n",
       "  ('calorie', {74: 91, 'Number': 'plur'})],\n",
       " [('what', {74: 91, 'PronType': 'int|rel'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('more', {74: 85, 'Degree': 'comp'}),\n",
       "  ('every', {74: 89}),\n",
       "  ('morning', {74: 91, 'Number': 'sing'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('practice',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('jog', {74: 99, 'Aspect': 'prog', 'Tense': 'pres', 'VerbForm': 'part'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('go',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('to', {74: 84}),\n",
       "  ('the', {74: 89}),\n",
       "  ('gym', {74: 91, 'Number': 'sing'})],\n",
       " [('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('lose', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('three', {74: 92, 'NumType': 'card'}),\n",
       "  ('kilo', {74: 91, 'Number': 'plur'}),\n",
       "  ('but', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('want',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('to', {74: 93, 'PartType': 'inf', 'VerbForm': 'inf'}),\n",
       "  ('lose', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('two', {74: 92, 'NumType': 'card'}),\n",
       "  ('kilo', {74: 91, 'Number': 'plur'}),\n",
       "  ('more', {74: 83, 'Degree': 'comp'})],\n",
       " [('everyone', {74: 91, 'Number': 'sing'}),\n",
       "  ('tell',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('her', {74: 94, 'PronType': 'prs'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('look',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('great', {74: 83, 'Degree': 'pos'}),\n",
       "  ('but', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('do',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('not', {74: 85, 'Degree': 'pos'}),\n",
       "  ('agree', {74: 99, 'VerbForm': 'inf'})],\n",
       " [('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('dream', {74: 99, 'Aspect': 'prog', 'Tense': 'pres', 'VerbForm': 'part'}),\n",
       "  ('about', {74: 84}),\n",
       "  ('a', {74: 89}),\n",
       "  ('slice', {74: 91, 'Number': 'sing'}),\n",
       "  ('of', {74: 84}),\n",
       "  ('wedding', {74: 91, 'Number': 'sing'}),\n",
       "  ('cake', {74: 91, 'Number': 'sing'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('do',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('not', {74: 85, 'Degree': 'pos'}),\n",
       "  ('want', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('to', {74: 93, 'PartType': 'inf', 'VerbForm': 'inf'}),\n",
       "  ('give', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('up', {74: 93})],\n",
       " [('dieting', {74: 91, 'Number': 'sing'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('not', {74: 85, 'Degree': 'pos'}),\n",
       "  ('easy', {74: 83, 'Degree': 'pos'})]]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_map = []\n",
    "for sentence in processed_ex:\n",
    "    sent_grammar_map = get_sent_gramm_features_map(sentence)\n",
    "    grammar_map.append(sent_grammar_map)\n",
    "grammar_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', {74: 89}),\n",
       " ('be',\n",
       "  {74: 99, 'Number': 'sing', 'Person': 3, 'Tense': 'pres', 'VerbForm': 'fin'}),\n",
       " ('my', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       " ('friend', {74: 91, 'Number': 'sing'}),\n",
       " ('jimmy', {74: 91, 'Number': 'sing'})]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_map[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('this', {74: 89}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('my', {74: 83, 'PronType': 'prs', 'Poss': 'yes'}), ('friend', {74: 91, 'Number': 'sing'}), ('jimmy', {74: 91, 'Number': 'sing'})]\n",
      "[('he', {74: 94, 'PronType': 'prs'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('from', {74: 84}), ('india', {74: 91, 'Number': 'sing'})]\n",
      "[('jimmy', {74: 91, 'Number': 'sing'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('a', {74: 89}), ('vegetarian', {74: 91, 'Number': 'sing'})]\n",
      "[('the', {74: 89}), ('good', {74: 83, 'Degree': 'sup'}), ('breakfast', {74: 91, 'Number': 'sing'}), ('for', {74: 84}), ('him', {74: 94, 'PronType': 'prs'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('a', {74: 89}), ('glass', {74: 91, 'Number': 'sing'}), ('of', {74: 84}), ('orange', {74: 83, 'Degree': 'pos'}), ('juice', {74: 91, 'Number': 'sing'}), ('two', {74: 92, 'NumType': 'card'}), ('apple', {74: 91, 'Number': 'plur'}), ('and', {74: 88, 'ConjType': 'coor'}), ('three', {74: 92, 'NumType': 'card'}), ('banana', {74: 91, 'Number': 'plur'})]\n",
      "[('jimmy', {74: 83, 'Degree': 'pos'}), ('like', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('watermelon', {74: 91, 'Number': 'plur'}), ('very', {74: 85, 'Degree': 'pos'}), ('much', {74: 85, 'Degree': 'pos'})]\n",
      "[('a', {74: 89}), ('watermelon', {74: 91, 'Number': 'sing'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('green', {74: 83, 'Degree': 'pos'}), ('outside', {74: 85, 'Degree': 'pos'}), ('and', {74: 88, 'ConjType': 'coor'}), ('red', {74: 83, 'Degree': 'pos'}), ('inside', {74: 91, 'Number': 'sing'})]\n",
      "[('it', {74: 94, 'PronType': 'prs'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('hard', {74: 83, 'Degree': 'pos'}), ('and', {74: 88, 'ConjType': 'coor'}), ('soft', {74: 83, 'Degree': 'pos'}), ('inside', {74: 84})]\n",
      "[('it', {74: 94, 'PronType': 'prs'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('juicy', {74: 83, 'Degree': 'pos'}), ('and', {74: 88, 'ConjType': 'coor'}), ('sweet', {74: 83, 'Degree': 'pos'})]\n",
      "[('what', {74: 91, 'PronType': 'int|rel'}), ('a', {74: 89}), ('lovely', {74: 83, 'Degree': 'pos'}), ('fruit', {74: 91, 'Number': 'sing'})]\n",
      "[('a', {74: 89}), ('month', {74: 91, 'Number': 'sing'}), ('ago', {74: 85, 'Degree': 'pos'}), ('sally', {74: 85, 'Degree': 'pos'}), ('receive', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('a', {74: 89}), ('letter', {74: 91, 'Number': 'sing'})]\n",
      "[('it', {74: 94, 'PronType': 'prs'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('an', {74: 89}), ('invitation', {74: 91, 'Number': 'sing'}), ('for', {74: 84}), ('a', {74: 89}), ('wedding', {74: 91, 'Number': 'sing'})]\n",
      "[('her', {74: 83, 'PronType': 'prs', 'Poss': 'yes'}), ('sister', {74: 91, 'Number': 'sing'}), ('victoria', {74: 91, 'Number': 'sing'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('get', {74: 99, 'VerbForm': 'part', 'Tense': 'pres', 'Aspect': 'prog'}), ('marry', {74: 99, 'VerbForm': 'part', 'Tense': 'past', 'Aspect': 'perf'})]\n",
      "[('last', {74: 83, 'Degree': 'pos'}), ('year', {74: 91, 'Number': 'sing'}), ('sally', {74: 85, 'Degree': 'pos'}), ('see', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('such', {74: 83, 'AdjType': 'pdt', 'PronType': 'prn'}), ('a', {74: 89}), ('ceremony', {74: 91, 'Number': 'sing'})]\n",
      "[('it', {74: 94, 'PronType': 'prs'}), ('take', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('place', {74: 91, 'Number': 'sing'}), ('on', {74: 84}), ('saturday', {74: 91, 'Number': 'sing'})]\n",
      "[('there', {74: 85, 'AdvType': 'ex'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('a', {74: 89}), ('lot', {74: 91, 'Number': 'sing'}), ('of', {74: 84}), ('guest', {74: 91, 'Number': 'plur'}), ('people', {74: 91, 'Number': 'plur'}), ('wear', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('nice', {74: 83, 'Degree': 'pos'}), ('clothe', {74: 91, 'Number': 'plur'}), ('meet', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('a', {74: 89}), ('husband', {74: 91, 'Number': 'sing'}), ('and', {74: 88, 'ConjType': 'coor'}), ('a', {74: 89}), ('wife', {74: 91, 'Number': 'sing'}), ('near', {74: 84}), ('the', {74: 89}), ('church', {74: 91, 'Number': 'sing'}), ('throw', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('confetti', {74: 91, 'Number': 'plur'}), ('eat', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('a', {74: 89}), ('very', {74: 85, 'Degree': 'pos'}), ('tasty', {74: 83, 'Degree': 'pos'}), ('cake', {74: 91, 'Number': 'sing'}), ('make', {74: 99, 'VerbForm': 'part', 'Tense': 'past', 'Aspect': 'perf'}), ('video', {74: 91, 'Number': 'plur'}), ('and', {74: 88, 'ConjType': 'coor'}), ('take', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('photo', {74: 91, 'Number': 'plur'})]\n",
      "[('in', {74: 84}), ('her', {74: 83, 'PronType': 'prs', 'Poss': 'yes'}), ('letter', {74: 91, 'Number': 'sing'}), ('victoria', {74: 91, 'Number': 'plur'}), ('ask', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('sally', {74: 85, 'Degree': 'pos'}), ('to', {74: 93, 'PartType': 'inf', 'VerbForm': 'inf'}), ('be', {74: 99, 'VerbForm': 'inf'}), ('her', {74: 83, 'PronType': 'prs', 'Poss': 'yes'}), ('bridesmaid', {74: 91, 'Number': 'sing'})]\n",
      "[('it', {74: 94, 'PronType': 'prs'}), ('mean', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('that', {74: 84}), ('on', {74: 84}), ('the', {74: 89}), ('day', {74: 91, 'Number': 'sing'}), ('of', {74: 84}), ('wedding', {74: 91, 'Number': 'sing'}), ('sally', {74: 85, 'Degree': 'pos'}), ('must', {74: 99, 'VerbType': 'mod'}), ('help', {74: 99, 'VerbForm': 'inf'}), ('victoria', {74: 99, 'VerbForm': 'inf'}), ('when', {74: 85, 'PronType': 'int|rel'}), ('she', {74: 94, 'PronType': 'prs'}), ('put', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('her', {74: 83, 'PronType': 'prs', 'Poss': 'yes'}), ('wedding', {74: 91, 'Number': 'sing'}), ('dress', {74: 91, 'Number': 'sing'}), ('on', {74: 84}), ('and', {74: 88, 'ConjType': 'coor'}), ('brush', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('her', {74: 83, 'PronType': 'prs', 'Poss': 'yes'}), ('hair', {74: 91, 'Number': 'sing'})]\n",
      "[('sally', {74: 85, 'Degree': 'pos'}), ('must', {74: 99, 'VerbType': 'mod'}), ('also', {74: 85, 'Degree': 'pos'}), ('accompany', {74: 99, 'VerbForm': 'inf'}), ('victoria', {74: 91, 'Number': 'plur'}), ('on', {74: 84}), ('her', {74: 83, 'PronType': 'prs', 'Poss': 'yes'}), ('way', {74: 91, 'Number': 'sing'}), ('to', {74: 84}), ('the', {74: 89}), ('church', {74: 91, 'Number': 'sing'}), ('and', {74: 88, 'ConjType': 'coor'}), ('carry', {74: 99, 'VerbForm': 'inf'}), ('a', {74: 89}), ('traditional', {74: 83, 'Degree': 'pos'}), ('bunch', {74: 91, 'Number': 'sing'}), ('of', {74: 84}), ('flower', {74: 91, 'Number': 'plur'})]\n",
      "[('sally', {74: 85, 'Degree': 'pos'}), ('agree', {74: 99, 'VerbForm': 'part', 'Tense': 'past', 'Aspect': 'perf'}), ('with', {74: 84}), ('pleasure', {74: 91, 'Number': 'sing'}), ('and', {74: 88, 'ConjType': 'coor'}), ('buy', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('a', {74: 89}), ('beautiful', {74: 83, 'Degree': 'pos'}), ('dress', {74: 91, 'Number': 'sing'}), ('for', {74: 84}), ('the', {74: 89}), ('ceremony', {74: 91, 'Number': 'sing'})]\n",
      "[('it', {74: 94, 'PronType': 'prs'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('white', {74: 83, 'Degree': 'pos'}), ('and', {74: 88, 'ConjType': 'coor'}), ('green', {74: 83, 'Degree': 'pos'}), ('with', {74: 84}), ('a', {74: 89}), ('long', {74: 85, 'Degree': 'pos'}), ('nice', {74: 83, 'Degree': 'pos'}), ('silk', {74: 91, 'Number': 'sing'}), ('skirt', {74: 91, 'Number': 'sing'})]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('but', {74: 88, 'ConjType': 'coor'}), ('at', {74: 84}), ('home', {74: 91, 'Number': 'sing'}), ('she', {74: 94, 'PronType': 'prs'}), ('understand', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('that', {74: 84}), ('she', {74: 94, 'PronType': 'prs'}), ('could', {74: 99, 'VerbType': 'mod'}), ('not', {74: 85, 'Degree': 'pos'}), ('fit', {74: 99, 'VerbForm': 'inf'}), ('into', {74: 84}), ('it', {74: 94, 'PronType': 'prs'})]\n",
      "[('what', {74: 91, 'PronType': 'int|rel'}), ('a', {74: 89}), ('pity', {74: 91, 'Number': 'sing'})]\n",
      "[('that', {74: 89}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('why', {74: 85, 'PronType': 'int|rel'}), ('sally', {74: 85, 'Degree': 'pos'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('on', {74: 84}), ('a', {74: 89}), ('diet', {74: 91, 'Number': 'sing'}), ('now', {74: 85, 'Degree': 'pos'})]\n",
      "[('she', {74: 94, 'PronType': 'prs'}), ('do', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('not', {74: 85, 'Degree': 'pos'}), ('eat', {74: 99, 'VerbForm': 'inf'}), ('cake', {74: 91, 'Number': 'plur'}), ('sweet', {74: 91, 'Number': 'plur'}), ('and', {74: 88, 'ConjType': 'coor'}), ('fry', {74: 99, 'VerbForm': 'part', 'Tense': 'past', 'Aspect': 'perf'}), ('potato', {74: 91, 'Number': 'plur'})]\n",
      "[('she', {74: 94, 'PronType': 'prs'}), ('do', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('not', {74: 85, 'Degree': 'pos'}), ('even', {74: 85, 'Degree': 'pos'}), ('eat', {74: 99, 'VerbForm': 'inf'}), ('some', {74: 89}), ('very', {74: 85, 'Degree': 'pos'}), ('sweet', {74: 83, 'Degree': 'pos'}), ('fruit', {74: 91, 'Number': 'sing'})]\n",
      "[('she', {74: 94, 'PronType': 'prs'}), ('cook', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('vegetable', {74: 91, 'Number': 'plur'}), ('fish', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres'}), ('and', {74: 88, 'ConjType': 'coor'}), ('boil', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('meat', {74: 91, 'Number': 'sing'})]\n",
      "[('she', {74: 94, 'PronType': 'prs'}), ('write', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('down', {74: 84}), ('everything', {74: 91, 'Number': 'sing'}), ('she', {74: 94, 'PronType': 'prs'}), ('eat', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('into', {74: 84}), ('a', {74: 89}), ('special', {74: 83, 'Degree': 'pos'}), ('notebook', {74: 91, 'Number': 'sing'}), ('and', {74: 88, 'ConjType': 'coor'}), ('add', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('up', {74: 93}), ('the', {74: 89}), ('calorie', {74: 91, 'Number': 'plur'})]\n",
      "[('what', {74: 91, 'PronType': 'int|rel'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('more', {74: 85, 'Degree': 'comp'}), ('every', {74: 89}), ('morning', {74: 91, 'Number': 'sing'}), ('she', {74: 94, 'PronType': 'prs'}), ('practice', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('jog', {74: 99, 'VerbForm': 'part', 'Tense': 'pres', 'Aspect': 'prog'}), ('and', {74: 88, 'ConjType': 'coor'}), ('go', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('to', {74: 84}), ('the', {74: 89}), ('gym', {74: 91, 'Number': 'sing'})]\n",
      "[('she', {74: 94, 'PronType': 'prs'}), ('lose', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}), ('three', {74: 92, 'NumType': 'card'}), ('kilo', {74: 91, 'Number': 'plur'}), ('but', {74: 88, 'ConjType': 'coor'}), ('she', {74: 94, 'PronType': 'prs'}), ('want', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('to', {74: 93, 'PartType': 'inf', 'VerbForm': 'inf'}), ('lose', {74: 99, 'VerbForm': 'inf'}), ('two', {74: 92, 'NumType': 'card'}), ('kilo', {74: 91, 'Number': 'plur'}), ('more', {74: 83, 'Degree': 'comp'})]\n",
      "[('everyone', {74: 91, 'Number': 'sing'}), ('tell', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('her', {74: 94, 'PronType': 'prs'}), ('she', {74: 94, 'PronType': 'prs'}), ('look', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('great', {74: 83, 'Degree': 'pos'}), ('but', {74: 88, 'ConjType': 'coor'}), ('she', {74: 94, 'PronType': 'prs'}), ('do', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('not', {74: 85, 'Degree': 'pos'}), ('agree', {74: 99, 'VerbForm': 'inf'})]\n",
      "[('she', {74: 94, 'PronType': 'prs'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('dream', {74: 99, 'VerbForm': 'part', 'Tense': 'pres', 'Aspect': 'prog'}), ('about', {74: 84}), ('a', {74: 89}), ('slice', {74: 91, 'Number': 'sing'}), ('of', {74: 84}), ('wedding', {74: 91, 'Number': 'sing'}), ('cake', {74: 91, 'Number': 'sing'}), ('and', {74: 88, 'ConjType': 'coor'}), ('do', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('not', {74: 85, 'Degree': 'pos'}), ('want', {74: 99, 'VerbForm': 'inf'}), ('to', {74: 93, 'PartType': 'inf', 'VerbForm': 'inf'}), ('give', {74: 99, 'VerbForm': 'inf'}), ('up', {74: 93})]\n",
      "[('dieting', {74: 91, 'Number': 'sing'}), ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres', 'Number': 'sing', 'Person': 3}), ('not', {74: 85, 'Degree': 'pos'}), ('easy', {74: 83, 'Degree': 'pos'})]\n"
     ]
    }
   ],
   "source": [
    "def get_lemm_text(text_gramm_map):\n",
    "    lemm_text = []\n",
    "    for sentence in text_gramm_map:\n",
    "        print(sentence)\n",
    "        sentence_lemm = ''\n",
    "        for word in sentence:\n",
    "            sentence_lemm += word[0] + ' '\n",
    "        sentence_lemm = sentence_lemm[:-1]\n",
    "        lemm_text.append(sentence_lemm)\n",
    "        \n",
    "    return lemm_text\n",
    "\n",
    "ex_text_lemm = get_lemm_text(grammar_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this be my friend jimmy',\n",
       " 'he be from india',\n",
       " 'jimmy be a vegetarian',\n",
       " 'the good breakfast for him be a glass of orange juice two apple and three banana',\n",
       " 'jimmy like watermelon very much',\n",
       " 'a watermelon be green outside and red inside',\n",
       " 'it be hard and soft inside',\n",
       " 'it be juicy and sweet',\n",
       " 'what a lovely fruit',\n",
       " 'a month ago sally receive a letter',\n",
       " 'it be an invitation for a wedding',\n",
       " 'her sister victoria be get marry',\n",
       " 'last year sally see such a ceremony',\n",
       " 'it take place on saturday',\n",
       " 'there be a lot of guest people wear nice clothe meet a husband and a wife near the church throw confetti eat a very tasty cake make video and take photo',\n",
       " 'in her letter victoria ask sally to be her bridesmaid',\n",
       " 'it mean that on the day of wedding sally must help victoria when she put her wedding dress on and brush her hair',\n",
       " 'sally must also accompany victoria on her way to the church and carry a traditional bunch of flower',\n",
       " 'sally agree with pleasure and buy a beautiful dress for the ceremony',\n",
       " 'it be white and green with a long nice silk skirt',\n",
       " 'but at home she understand that she could not fit into it',\n",
       " 'what a pity',\n",
       " 'that be why sally be on a diet now',\n",
       " 'she do not eat cake sweet and fry potato',\n",
       " 'she do not even eat some very sweet fruit',\n",
       " 'she cook vegetable fish and boil meat',\n",
       " 'she write down everything she eat into a special notebook and add up the calorie',\n",
       " 'what be more every morning she practice jog and go to the gym',\n",
       " 'she lose three kilo but she want to lose two kilo more',\n",
       " 'everyone tell her she look great but she do not agree',\n",
       " 'she be dream about a slice of wedding cake and do not want to give up',\n",
       " 'dieting be not easy']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_text_lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_tfidf(feature_names, sorted_items):\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf_dict(lemm_lines_list):\n",
    "    cv=CountVectorizer(max_df=0.85,stop_words=set(stopwords.words('english')))\n",
    "    word_count_vector=cv.fit_transform(lemm_lines_list)\n",
    "    \n",
    "    tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "    tfidf_transformer.fit(word_count_vector)\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform(ex_text_lemm))\n",
    "    \n",
    "    feature_names=cv.get_feature_names()\n",
    "    \n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "    \n",
    "    words_tf_idf=extract_tfidf(feature_names,sorted_items)\n",
    "    \n",
    "    return words_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accompany': 0.323,\n",
       " 'add': 0.39,\n",
       " 'ago': 0.488,\n",
       " 'agree': 0.371,\n",
       " 'also': 0.323,\n",
       " 'apple': 0.341,\n",
       " 'ask': 0.514,\n",
       " 'banana': 0.341,\n",
       " 'beautiful': 0.415,\n",
       " 'boil': 0.447,\n",
       " 'breakfast': 0.341,\n",
       " 'bridesmaid': 0.514,\n",
       " 'brush': 0.298,\n",
       " 'bunch': 0.323,\n",
       " 'buy': 0.415,\n",
       " 'cake': 0.189,\n",
       " 'calorie': 0.39,\n",
       " 'carry': 0.323,\n",
       " 'ceremony': 0.371,\n",
       " 'church': 0.207,\n",
       " 'clothe': 0.232,\n",
       " 'confetti': 0.232,\n",
       " 'cook': 0.447,\n",
       " 'could': 0.5,\n",
       " 'day': 0.298,\n",
       " 'diet': 0.844,\n",
       " 'dieting': 0.707,\n",
       " 'dream': 0.441,\n",
       " 'dress': 0.266,\n",
       " 'easy': 0.707,\n",
       " 'eat': 0.176,\n",
       " 'even': 0.573,\n",
       " 'every': 0.408,\n",
       " 'everyone': 0.457,\n",
       " 'everything': 0.39,\n",
       " 'fish': 0.447,\n",
       " 'fit': 0.5,\n",
       " 'flower': 0.323,\n",
       " 'friend': 0.774,\n",
       " 'fruit': 0.512,\n",
       " 'fry': 0.505,\n",
       " 'get': 0.529,\n",
       " 'give': 0.441,\n",
       " 'glass': 0.341,\n",
       " 'go': 0.408,\n",
       " 'good': 0.341,\n",
       " 'great': 0.457,\n",
       " 'green': 0.378,\n",
       " 'guest': 0.232,\n",
       " 'gym': 0.408,\n",
       " 'hair': 0.298,\n",
       " 'hard': 0.598,\n",
       " 'help': 0.298,\n",
       " 'home': 0.5,\n",
       " 'husband': 0.232,\n",
       " 'india': 1.0,\n",
       " 'inside': 0.426,\n",
       " 'invitation': 0.774,\n",
       " 'jimmy': 0.439,\n",
       " 'jog': 0.408,\n",
       " 'juice': 0.341,\n",
       " 'juicy': 0.774,\n",
       " 'kilo': 0.62,\n",
       " 'last': 0.488,\n",
       " 'letter': 0.436,\n",
       " 'like': 0.537,\n",
       " 'long': 0.423,\n",
       " 'look': 0.457,\n",
       " 'lose': 0.62,\n",
       " 'lot': 0.232,\n",
       " 'lovely': 0.746,\n",
       " 'make': 0.232,\n",
       " 'marry': 0.529,\n",
       " 'mean': 0.298,\n",
       " 'meat': 0.447,\n",
       " 'meet': 0.232,\n",
       " 'month': 0.488,\n",
       " 'morning': 0.408,\n",
       " 'much': 0.537,\n",
       " 'must': 0.266,\n",
       " 'near': 0.232,\n",
       " 'nice': 0.207,\n",
       " 'notebook': 0.39,\n",
       " 'orange': 0.341,\n",
       " 'outside': 0.477,\n",
       " 'people': 0.232,\n",
       " 'photo': 0.232,\n",
       " 'pity': 1.0,\n",
       " 'place': 0.598,\n",
       " 'pleasure': 0.415,\n",
       " 'potato': 0.505,\n",
       " 'practice': 0.408,\n",
       " 'put': 0.298,\n",
       " 'receive': 0.488,\n",
       " 'red': 0.477,\n",
       " 'sally': 0.189,\n",
       " 'saturday': 0.598,\n",
       " 'see': 0.488,\n",
       " 'silk': 0.423,\n",
       " 'sister': 0.529,\n",
       " 'skirt': 0.423,\n",
       " 'slice': 0.441,\n",
       " 'soft': 0.598,\n",
       " 'special': 0.39,\n",
       " 'sweet': 0.413,\n",
       " 'take': 0.207,\n",
       " 'tasty': 0.232,\n",
       " 'tell': 0.457,\n",
       " 'three': 0.277,\n",
       " 'throw': 0.232,\n",
       " 'traditional': 0.323,\n",
       " 'two': 0.277,\n",
       " 'understand': 0.5,\n",
       " 'vegetable': 0.447,\n",
       " 'vegetarian': 0.774,\n",
       " 'victoria': 0.226,\n",
       " 'video': 0.232,\n",
       " 'want': 0.277,\n",
       " 'watermelon': 0.426,\n",
       " 'way': 0.323,\n",
       " 'wear': 0.232,\n",
       " 'wedding': 0.361,\n",
       " 'white': 0.423,\n",
       " 'wife': 0.232,\n",
       " 'write': 0.39,\n",
       " 'year': 0.488}"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_dict = get_tf_idf_dict(ex_text_lemm)\n",
    "tf_idf_dict"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "РАЗБОР ВНЕ КАТЕГОРИЙ  ВОЗМОЖНЫМ Н-ГРАММНЫМ ИЗВЛЕЧЕНИЕМ"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ОПРЕДЕЛИТЬСЯ С ГРАММАТИКОЙ \n",
    "\n",
    "PRES PERFECT v3 \n",
    "'Aspect': 'perf'\n",
    "\n",
    "FUTURE CONTINIOUS \n",
    "WILL BE V+ING\n",
    "\n",
    "'Aspect': 'prog' + проверять два предыдущих слова\n",
    "\n",
    "PAST CONTINIOUS\n",
    "WERE WAS v+ING\n",
    "'Aspect': 'prog' + проверять пред слово\n",
    "were / was be {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Phrasal verbs искать глагол в двух предыдущих словах (лучше конечно вообще делать грамм парсинг для этого убивать именную группу и без нее искать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrasal_list = []\n",
    "with open(\"phrasal_verbs.txt\", \"r\") as pv_doc:\n",
    "    for pv in pv_doc:\n",
    "        phrasal_list.append(pv[:-1])\n",
    "#phrasal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "все это делать внутри грамматической карты предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'weight': 0, 'word': 'i'},\n",
       "  {'weight': 0, 'word': 'have'},\n",
       "  {'weight': 0, 'word': 'get'},\n",
       "  {'weight': 0, 'word': 'marry'}],\n",
       " [{'weight': 0, 'word': 'i'},\n",
       "  {'weight': 0, 'word': 'have'},\n",
       "  {'weight': 0, 'word': 'go'},\n",
       "  {'weight': 0, 'word': 'there'}],\n",
       " [{'weight': 0, 'word': 'i'},\n",
       "  {'weight': 0, 'word': 'will'},\n",
       "  {'weight': 0, 'word': 'be'},\n",
       "  {'weight': 0, 'word': 'do'},\n",
       "  {'weight': 0, 'word': 'that'}],\n",
       " [{'weight': 0, 'word': 'i'},\n",
       "  {'weight': 0, 'word': 'make'},\n",
       "  {'weight': 0, 'word': 'it'},\n",
       "  {'weight': 0, 'word': 'up'}],\n",
       " [{'weight': 0, 'word': 'do'},\n",
       "  {'weight': 0, 'word': 'that'},\n",
       "  {'weight': 0, 'word': 'be'},\n",
       "  {'weight': 0, 'word': 'not'},\n",
       "  {'weight': 0, 'word': 'my'},\n",
       "  {'weight': 0, 'word': 'hobby'}],\n",
       " [{'weight': 0, 'word': 'I'},\n",
       "  {'weight': 0, 'word': 'be'},\n",
       "  {'weight': 0, 'word': 'do'},\n",
       "  {'weight': 0, 'word': 'it'},\n",
       "  {'weight': 0, 'word': 'whole'},\n",
       "  {'weight': 0, 'word': 'day'}],\n",
       " [{'weight': 0, 'word': 'I'},\n",
       "  {'weight': 0, 'word': 'will'},\n",
       "  {'weight': 0, 'word': 'pick'},\n",
       "  {'weight': 0, 'word': 'you'},\n",
       "  {'weight': 0, 'word': 'up'}]]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_weights_empty_list(gramm_map_text):\n",
    "    weights_list = []\n",
    "    for sentence in gramm_map_text:\n",
    "        #print(sentence)\n",
    "        sentence_weights = []\n",
    "        for element in sentence:\n",
    "            weight = {\"word\" : element[0], \"weight\": 0}\n",
    "            sentence_weights.append(weight)\n",
    "        weights_list.append(sentence_weights)\n",
    "    return weights_list\n",
    "test_weights = get_weights_empty_list(grammar_map_test)\n",
    "test_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('i', {74: 94, 'PronType': 'prs'}),\n",
       "  ('have', {74: 99, 'Tense': 'pres', 'VerbForm': 'fin'}),\n",
       "  ('go', {74: 99, 'Aspect': 'perf', 'Tense': 'past', 'VerbForm': 'part'}),\n",
       "  ('there', {74: 85, 'Degree': 'pos'})],\n",
       " [('i', {74: 94, 'PronType': 'prs'}),\n",
       "  ('will', {74: 99, 'VerbType': 'mod'}),\n",
       "  ('be', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('do', {74: 99, 'Aspect': 'prog', 'Tense': 'pres', 'VerbForm': 'part'}),\n",
       "  ('that', {74: 89})],\n",
       " [('i', {74: 94, 'PronType': 'prs'}),\n",
       "  ('make', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('up', {74: 93})]]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_map_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'i': None}, {'have': None}, {'go': None}, {'there': None}],\n",
       " [{'i': None}, {'will': None}, {'be': None}, {'do': None}, {'that': None}],\n",
       " [{'i': None}, {'make': None}, {'it': None}, {'up': None}]]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('i', {74: 94, 'PronType': 'prs'}),\n",
       "  ('have', {74: 99, 'Tense': 'pres', 'VerbForm': 'fin'}),\n",
       "  ('get', {74: 99, 'Aspect': 'perf', 'Tense': 'past', 'VerbForm': 'part'}),\n",
       "  ('marry', {74: 99, 'Aspect': 'perf', 'Tense': 'past', 'VerbForm': 'part'})],\n",
       " [('i', {74: 94, 'PronType': 'prs'}),\n",
       "  ('have', {74: 99, 'Tense': 'pres', 'VerbForm': 'fin'}),\n",
       "  ('go', {74: 99, 'Aspect': 'perf', 'Tense': 'past', 'VerbForm': 'part'}),\n",
       "  ('there', {74: 85, 'Degree': 'pos'})],\n",
       " [('i', {74: 94, 'PronType': 'prs'}),\n",
       "  ('will', {74: 99, 'VerbType': 'mod'}),\n",
       "  ('be', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('do', {74: 99, 'Aspect': 'prog', 'Tense': 'pres', 'VerbForm': 'part'}),\n",
       "  ('that', {74: 89})],\n",
       " [('i', {74: 94, 'PronType': 'prs'}),\n",
       "  ('make', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('up', {74: 93})],\n",
       " [('do', {74: 99, 'Aspect': 'prog', 'Tense': 'pres', 'VerbForm': 'part'}),\n",
       "  ('that', {74: 89}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('not', {74: 85, 'Degree': 'pos'}),\n",
       "  ('my', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('hobby', {74: 91, 'Number': 'sing'})],\n",
       " [('I', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('do', {74: 99, 'Aspect': 'prog', 'Tense': 'pres', 'VerbForm': 'part'}),\n",
       "  ('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('whole', {74: 83, 'Degree': 'pos'}),\n",
       "  ('day', {74: 91, 'Number': 'sing'})],\n",
       " [('I', {74: 94, 'PronType': 'prs'}),\n",
       "  ('will', {74: 99, 'VerbType': 'mod'}),\n",
       "  ('pick', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('you', {74: 94, 'PronType': 'prs'}),\n",
       "  ('up', {74: 93})]]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_test_text = ['i have got married', 'i have gone there', 'i will be doing that', 'i made it up', 'doing that is not my hobby','I was doing it whole day', 'I will pick you up']\n",
    "grammar_map_test = []\n",
    "for sentence in adjusted_test_text:\n",
    "    sent_grammar_map = get_sent_gramm_features_map(sentence)\n",
    "    grammar_map_test.append(sent_grammar_map)\n",
    "grammar_map_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRESENT PERFECT\n",
      "('have', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres'})\n",
      "('get', {74: 99, 'VerbForm': 'part', 'Tense': 'past', 'Aspect': 'perf'})\n",
      "PRESENT PERFECT\n",
      "('get', {74: 99, 'VerbForm': 'part', 'Tense': 'past', 'Aspect': 'perf'})\n",
      "('marry', {74: 99, 'VerbForm': 'part', 'Tense': 'past', 'Aspect': 'perf'})\n",
      "PRESENT PERFECT\n",
      "('have', {74: 99, 'VerbForm': 'fin', 'Tense': 'pres'})\n",
      "('go', {74: 99, 'VerbForm': 'part', 'Tense': 'past', 'Aspect': 'perf'})\n",
      "FUTURE CONTINIOUS\n",
      "prev word is ('will', {74: 99, 'VerbType': 'mod'})\n",
      "prev word is ('be', {74: 99, 'VerbForm': 'inf'})\n",
      "('do', {74: 99, 'VerbForm': 'part', 'Tense': 'pres', 'Aspect': 'prog'})\n",
      "PAST CONTINIOUS\n",
      "('do', {74: 99, 'VerbForm': 'part', 'Tense': 'pres', 'Aspect': 'prog'})\n",
      "prev word is ('be', {74: 99, 'VerbForm': 'fin', 'Tense': 'past'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'weight': 0, 'word': 'i'},\n",
       "  {'diff_grammar': 'pr_perf', 'weight': 0, 'word': 'have'},\n",
       "  {'diff_grammar': 'pr_perf', 'weight': 0, 'word': 'get'},\n",
       "  {'diff_grammar': 'pr_perf', 'weight': 0, 'word': 'marry'}],\n",
       " [{'weight': 0, 'word': 'i'},\n",
       "  {'diff_grammar': 'pr_perf', 'weight': 0, 'word': 'have'},\n",
       "  {'diff_grammar': 'pr_perf', 'weight': 0, 'word': 'go'},\n",
       "  {'weight': 0, 'word': 'there'}],\n",
       " [{'weight': 0, 'word': 'i'},\n",
       "  {'diff_grammar': 'fut_cont', 'weight': 0, 'word': 'will'},\n",
       "  {'diff_grammar': 'fut_cont', 'weight': 0, 'word': 'be'},\n",
       "  {'diff_grammar': 'fut_cont', 'weight': 0, 'word': 'do'},\n",
       "  {'weight': 0, 'word': 'that'}],\n",
       " [{'weight': 0, 'word': 'i'},\n",
       "  {'weight': 0, 'word': 'make'},\n",
       "  {'weight': 0, 'word': 'it'},\n",
       "  {'weight': 0, 'word': 'up'}],\n",
       " [{'weight': 0, 'word': 'do'},\n",
       "  {'weight': 0, 'word': 'that'},\n",
       "  {'weight': 0, 'word': 'be'},\n",
       "  {'weight': 0, 'word': 'not'},\n",
       "  {'weight': 0, 'word': 'my'},\n",
       "  {'weight': 0, 'word': 'hobby'}],\n",
       " [{'weight': 0, 'word': 'I'},\n",
       "  {'diff_grammar': 'past_cont', 'weight': 0, 'word': 'be'},\n",
       "  {'diff_grammar': 'past_cont', 'weight': 0, 'word': 'do'},\n",
       "  {'weight': 0, 'word': 'it'},\n",
       "  {'weight': 0, 'word': 'whole'},\n",
       "  {'weight': 0, 'word': 'day'}],\n",
       " [{'weight': 0, 'word': 'I'},\n",
       "  {'weight': 0, 'word': 'will'},\n",
       "  {'weight': 0, 'word': 'pick'},\n",
       "  {'weight': 0, 'word': 'you'},\n",
       "  {'weight': 0, 'word': 'up'}]]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_difficult_grammar(text_grammar_map, weights_list, debug = False):\n",
    "    for sentence_grammar_map, sentence_weights in zip(text_grammar_map,weights_list):\n",
    "        for el_ind in range(len(sentence_grammar_map)):\n",
    "            #print(sentence_grammar_map[el_ind])\n",
    "            \n",
    "            if('Aspect' in sentence_grammar_map[el_ind][1]):\n",
    "                #present perfect\n",
    "                if ( sentence_grammar_map[el_ind][1]['Aspect'] == 'perf' ):\n",
    "                    if(sentence_grammar_map[el_ind - 2][0] == 'have' or sentence_grammar_map[el_ind - 1][0] == 'have'):\n",
    "                        if(debug): print(\"PRESENT PERFECT\")\n",
    "                        if(debug): print(sentence_grammar_map[el_ind - 1])\n",
    "                        if(debug): print(sentence_grammar_map[el_ind])\n",
    "\n",
    "                        sentence_weights[el_ind][\"diff_grammar\"] = \"pr_perf\"\n",
    "                        sentence_weights[el_ind - 1][\"diff_grammar\"] = \"pr_perf\"\n",
    "                \n",
    "                \n",
    "                elif(sentence_grammar_map[el_ind][1]['Aspect'] == 'prog'):\n",
    "                    #future continious check \"will + be + v-ing\"\n",
    "                    if (sentence_grammar_map[el_ind - 1][0] == 'be' and sentence_grammar_map[el_ind - 2][0] == 'will'):\n",
    "                        if(debug): print(\"FUTURE CONTINIOUS\")                       \n",
    "                        if(debug): print(\"prev word is\", sentence_grammar_map[el_ind - 2])\n",
    "                        if(debug): print(\"prev word is\", sentence_grammar_map[el_ind - 1])\n",
    "                        if(debug): print(sentence_grammar_map[el_ind])\n",
    "                        sentence_weights[el_ind][\"diff_grammar\"] = \"fut_cont\"\n",
    "                        sentence_weights[el_ind - 1][\"diff_grammar\"] = \"fut_cont\"\n",
    "                        sentence_weights[el_ind - 2][\"diff_grammar\"] = \"fut_cont\"\n",
    "                   #past continious was/were + v-ing\"     \n",
    "                    elif (sentence_grammar_map[el_ind - 1][0] == 'be' and sentence_grammar_map[el_ind -1][1]['Tense'] == 'past'):\n",
    "                        if(debug): print(\"PAST CONTINIOUS\")\n",
    "                        if(debug): print(sentence_grammar_map[el_ind])\n",
    "                        if(debug): print(\"prev word is\", sentence_grammar_map[el_ind - 1])\n",
    "                        sentence_weights[el_ind][\"diff_grammar\"] = \"past_cont\"\n",
    "                        sentence_weights[el_ind - 1][\"diff_grammar\"] = \"past_cont\"\n",
    "                        \n",
    "                \n",
    "    return weights_list\n",
    "\n",
    "get_difficult_grammar(grammar_map_test,test_weights, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrasal Verb found: make up\n",
      "Phrasal Verb found: pick up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'weight': 0, 'word': 'i'},\n",
       "  {'diff_grammar': 'pr_perf', 'weight': 0, 'word': 'have'},\n",
       "  {'diff_grammar': 'pr_perf', 'weight': 0, 'word': 'get'},\n",
       "  {'diff_grammar': 'pr_perf', 'weight': 0, 'word': 'marry'}],\n",
       " [{'weight': 0, 'word': 'i'},\n",
       "  {'diff_grammar': 'pr_perf', 'weight': 0, 'word': 'have'},\n",
       "  {'diff_grammar': 'pr_perf', 'weight': 0, 'word': 'go'},\n",
       "  {'weight': 0, 'word': 'there'}],\n",
       " [{'weight': 0, 'word': 'i'},\n",
       "  {'diff_grammar': 'fut_cont', 'weight': 0, 'word': 'will'},\n",
       "  {'diff_grammar': 'fut_cont', 'weight': 0, 'word': 'be'},\n",
       "  {'diff_grammar': 'fut_cont', 'weight': 0, 'word': 'do'},\n",
       "  {'weight': 0, 'word': 'that'}],\n",
       " [{'weight': 0, 'word': 'i'},\n",
       "  {'phrasal_verb': 'yes', 'weight': 0, 'word': 'make'},\n",
       "  {'phrasal_verb': 'yes', 'weight': 0, 'word': 'it'},\n",
       "  {'phrasal_verb': 'yes', 'weight': 0, 'word': 'up'}],\n",
       " [{'weight': 0, 'word': 'do'},\n",
       "  {'weight': 0, 'word': 'that'},\n",
       "  {'weight': 0, 'word': 'be'},\n",
       "  {'weight': 0, 'word': 'not'},\n",
       "  {'weight': 0, 'word': 'my'},\n",
       "  {'weight': 0, 'word': 'hobby'}],\n",
       " [{'weight': 0, 'word': 'I'},\n",
       "  {'diff_grammar': 'past_cont', 'weight': 0, 'word': 'be'},\n",
       "  {'diff_grammar': 'past_cont', 'weight': 0, 'word': 'do'},\n",
       "  {'weight': 0, 'word': 'it'},\n",
       "  {'weight': 0, 'word': 'whole'},\n",
       "  {'weight': 0, 'word': 'day'}],\n",
       " [{'weight': 0, 'word': 'I'},\n",
       "  {'weight': 0, 'word': 'will'},\n",
       "  {'phrasal_verb': 'yes', 'weight': 0, 'word': 'pick'},\n",
       "  {'weight': 0, 'word': 'you'},\n",
       "  {'phrasal_verb': 'yes', 'weight': 0, 'word': 'up'}]]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_phrasal_verbs(text_grammar_map, weights_list, debug = False):\n",
    "    for sentence_grammar_map, sentence_weights in zip(text_grammar_map,weights_list):\n",
    "        for el_ind in range(1, len(sentence_grammar_map)):  \n",
    "            for searh_ind in range(1, 3):\n",
    "                try_phrase = sentence_grammar_map[el_ind - searh_ind][0] + ' ' + sentence_grammar_map[el_ind][0]\n",
    "                #print(try_phrase)\n",
    "                if(try_phrase in phrasal_list):\n",
    "                    if(debug): print(\"Phrasal Verb found:\", try_phrase)\n",
    "                    sentence_weights[el_ind][\"phrasal_verb\"] = \"yes\"\n",
    "                    sentence_weights[el_ind - searh_ind][\"phrasal_verb\"] = \"yes\"\n",
    "    return weights_list\n",
    "        #print(\"\\n\")\n",
    "get_phrasal_verbs(grammar_map_test,test_weights,debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I {74: 94, 'PronType': 'prs'}\n",
      "were be {74: 99, 'VerbForm': 'fin', 'Tense': 'past'}\n",
      "going go {74: 99, 'VerbForm': 'part', 'Tense': 'pres', 'Aspect': 'prog'}\n",
      "there there {74: 85, 'Degree': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I were going there\")\n",
    "for token in doc:\n",
    "    if(token.lemma_[0] == \"-\"):\n",
    "        token.lemma_ = token.text\n",
    "    print(token.text, token.lemma_, nlp.vocab.morphology.tag_map[token.tag_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# СЧИТАЕМ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "сначала даем веса фразовым глаголам\n",
    "затем даем веса по тфидф если веса нет то даем 0,1\n",
    "затем "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ИТЕРРИРУЕМСЯ ПО ЛЕММАТИЗИРОВАННОМУ ТЕКСТУ ВНУТРИ КАЖДОГО ПРЕДЛОЖЕНИЯ\n",
    "ПРОВЕРЯЕМ ГРАММ ФИЧИ ПО СООТВЕТСВУЮЩЕУ ИНДЕКСУ\n",
    "ТАКЖЕ ПРОВЕРЯЕМ ТФДФ ИНДЕКСЫ\n",
    "ЕСЛИ СЛОВО ОТСУТСТВУЕТ В ТФИДФ ТО ДАЕМ ЕМУ МИНИМАЛЬНЫЙ ВЕС ТИПА 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{74: 89}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_map[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('this', {74: 89}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('my', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('friend', {74: 91, 'Number': 'sing'}),\n",
       "  ('jimmy', {74: 91, 'Number': 'sing'})],\n",
       " [('he', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('from', {74: 84}),\n",
       "  ('india', {74: 91, 'Number': 'sing'})],\n",
       " [('jimmy', {74: 91, 'Number': 'sing'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('vegetarian', {74: 91, 'Number': 'sing'})],\n",
       " [('the', {74: 89}),\n",
       "  ('good', {74: 83, 'Degree': 'sup'}),\n",
       "  ('breakfast', {74: 91, 'Number': 'sing'}),\n",
       "  ('for', {74: 84}),\n",
       "  ('him', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('glass', {74: 91, 'Number': 'sing'}),\n",
       "  ('of', {74: 84}),\n",
       "  ('orange', {74: 83, 'Degree': 'pos'}),\n",
       "  ('juice', {74: 91, 'Number': 'sing'}),\n",
       "  ('two', {74: 92, 'NumType': 'card'}),\n",
       "  ('apple', {74: 91, 'Number': 'plur'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('three', {74: 92, 'NumType': 'card'}),\n",
       "  ('banana', {74: 91, 'Number': 'plur'})],\n",
       " [('jimmy', {74: 83, 'Degree': 'pos'}),\n",
       "  ('like',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('watermelon', {74: 91, 'Number': 'plur'}),\n",
       "  ('very', {74: 85, 'Degree': 'pos'}),\n",
       "  ('much', {74: 85, 'Degree': 'pos'})],\n",
       " [('a', {74: 89}),\n",
       "  ('watermelon', {74: 91, 'Number': 'sing'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('green', {74: 83, 'Degree': 'pos'}),\n",
       "  ('outside', {74: 85, 'Degree': 'pos'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('red', {74: 83, 'Degree': 'pos'}),\n",
       "  ('inside', {74: 91, 'Number': 'sing'})],\n",
       " [('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('hard', {74: 83, 'Degree': 'pos'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('soft', {74: 83, 'Degree': 'pos'}),\n",
       "  ('inside', {74: 84})],\n",
       " [('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('juicy', {74: 83, 'Degree': 'pos'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('sweet', {74: 83, 'Degree': 'pos'})],\n",
       " [('what', {74: 91, 'PronType': 'int|rel'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('lovely', {74: 83, 'Degree': 'pos'}),\n",
       "  ('fruit', {74: 91, 'Number': 'sing'})],\n",
       " [('a', {74: 89}),\n",
       "  ('month', {74: 91, 'Number': 'sing'}),\n",
       "  ('ago', {74: 85, 'Degree': 'pos'}),\n",
       "  ('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('receive', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('letter', {74: 91, 'Number': 'sing'})],\n",
       " [('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('an', {74: 89}),\n",
       "  ('invitation', {74: 91, 'Number': 'sing'}),\n",
       "  ('for', {74: 84}),\n",
       "  ('a', {74: 89}),\n",
       "  ('wedding', {74: 91, 'Number': 'sing'})],\n",
       " [('her', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('sister', {74: 91, 'Number': 'sing'}),\n",
       "  ('victoria', {74: 91, 'Number': 'sing'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('get', {74: 99, 'Aspect': 'prog', 'Tense': 'pres', 'VerbForm': 'part'}),\n",
       "  ('marry', {74: 99, 'Aspect': 'perf', 'Tense': 'past', 'VerbForm': 'part'})],\n",
       " [('last', {74: 83, 'Degree': 'pos'}),\n",
       "  ('year', {74: 91, 'Number': 'sing'}),\n",
       "  ('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('see', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('such', {74: 83, 'AdjType': 'pdt', 'PronType': 'prn'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('ceremony', {74: 91, 'Number': 'sing'})],\n",
       " [('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('take', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('place', {74: 91, 'Number': 'sing'}),\n",
       "  ('on', {74: 84}),\n",
       "  ('saturday', {74: 91, 'Number': 'sing'})],\n",
       " [('there', {74: 85, 'AdvType': 'ex'}),\n",
       "  ('be', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('lot', {74: 91, 'Number': 'sing'}),\n",
       "  ('of', {74: 84}),\n",
       "  ('guest', {74: 91, 'Number': 'plur'}),\n",
       "  ('people', {74: 91, 'Number': 'plur'}),\n",
       "  ('wear', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('nice', {74: 83, 'Degree': 'pos'}),\n",
       "  ('clothe', {74: 91, 'Number': 'plur'}),\n",
       "  ('meet', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('husband', {74: 91, 'Number': 'sing'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('wife', {74: 91, 'Number': 'sing'}),\n",
       "  ('near', {74: 84}),\n",
       "  ('the', {74: 89}),\n",
       "  ('church', {74: 91, 'Number': 'sing'}),\n",
       "  ('throw', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('confetti', {74: 91, 'Number': 'plur'}),\n",
       "  ('eat', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('very', {74: 85, 'Degree': 'pos'}),\n",
       "  ('tasty', {74: 83, 'Degree': 'pos'}),\n",
       "  ('cake', {74: 91, 'Number': 'sing'}),\n",
       "  ('make', {74: 99, 'Aspect': 'perf', 'Tense': 'past', 'VerbForm': 'part'}),\n",
       "  ('video', {74: 91, 'Number': 'plur'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('take', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('photo', {74: 91, 'Number': 'plur'})],\n",
       " [('in', {74: 84}),\n",
       "  ('her', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('letter', {74: 91, 'Number': 'sing'}),\n",
       "  ('victoria', {74: 91, 'Number': 'plur'}),\n",
       "  ('ask', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('to', {74: 93, 'PartType': 'inf', 'VerbForm': 'inf'}),\n",
       "  ('be', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('her', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('bridesmaid', {74: 91, 'Number': 'sing'})],\n",
       " [('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('mean',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('that', {74: 84}),\n",
       "  ('on', {74: 84}),\n",
       "  ('the', {74: 89}),\n",
       "  ('day', {74: 91, 'Number': 'sing'}),\n",
       "  ('of', {74: 84}),\n",
       "  ('wedding', {74: 91, 'Number': 'sing'}),\n",
       "  ('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('must', {74: 99, 'VerbType': 'mod'}),\n",
       "  ('help', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('victoria', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('when', {74: 85, 'PronType': 'int|rel'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('put',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('her', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('wedding', {74: 91, 'Number': 'sing'}),\n",
       "  ('dress', {74: 91, 'Number': 'sing'}),\n",
       "  ('on', {74: 84}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('brush',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('her', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('hair', {74: 91, 'Number': 'sing'})],\n",
       " [('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('must', {74: 99, 'VerbType': 'mod'}),\n",
       "  ('also', {74: 85, 'Degree': 'pos'}),\n",
       "  ('accompany', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('victoria', {74: 91, 'Number': 'plur'}),\n",
       "  ('on', {74: 84}),\n",
       "  ('her', {74: 83, 'Poss': 'yes', 'PronType': 'prs'}),\n",
       "  ('way', {74: 91, 'Number': 'sing'}),\n",
       "  ('to', {74: 84}),\n",
       "  ('the', {74: 89}),\n",
       "  ('church', {74: 91, 'Number': 'sing'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('carry', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('traditional', {74: 83, 'Degree': 'pos'}),\n",
       "  ('bunch', {74: 91, 'Number': 'sing'}),\n",
       "  ('of', {74: 84}),\n",
       "  ('flower', {74: 91, 'Number': 'plur'})],\n",
       " [('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('agree', {74: 99, 'Aspect': 'perf', 'Tense': 'past', 'VerbForm': 'part'}),\n",
       "  ('with', {74: 84}),\n",
       "  ('pleasure', {74: 91, 'Number': 'sing'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('buy', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('beautiful', {74: 83, 'Degree': 'pos'}),\n",
       "  ('dress', {74: 91, 'Number': 'sing'}),\n",
       "  ('for', {74: 84}),\n",
       "  ('the', {74: 89}),\n",
       "  ('ceremony', {74: 91, 'Number': 'sing'})],\n",
       " [('it', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('white', {74: 83, 'Degree': 'pos'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('green', {74: 83, 'Degree': 'pos'}),\n",
       "  ('with', {74: 84}),\n",
       "  ('a', {74: 89}),\n",
       "  ('long', {74: 85, 'Degree': 'pos'}),\n",
       "  ('nice', {74: 83, 'Degree': 'pos'}),\n",
       "  ('silk', {74: 91, 'Number': 'sing'}),\n",
       "  ('skirt', {74: 91, 'Number': 'sing'})],\n",
       " [('but', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('at', {74: 84}),\n",
       "  ('home', {74: 91, 'Number': 'sing'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('understand', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('that', {74: 84}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('could', {74: 99, 'VerbType': 'mod'}),\n",
       "  ('not', {74: 85, 'Degree': 'pos'}),\n",
       "  ('fit', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('into', {74: 84}),\n",
       "  ('it', {74: 94, 'PronType': 'prs'})],\n",
       " [('what', {74: 91, 'PronType': 'int|rel'}),\n",
       "  ('a', {74: 89}),\n",
       "  ('pity', {74: 91, 'Number': 'sing'})],\n",
       " [('that', {74: 89}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('why', {74: 85, 'PronType': 'int|rel'}),\n",
       "  ('sally', {74: 85, 'Degree': 'pos'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('on', {74: 84}),\n",
       "  ('a', {74: 89}),\n",
       "  ('diet', {74: 91, 'Number': 'sing'}),\n",
       "  ('now', {74: 85, 'Degree': 'pos'})],\n",
       " [('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('do',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('not', {74: 85, 'Degree': 'pos'}),\n",
       "  ('eat', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('cake', {74: 91, 'Number': 'plur'}),\n",
       "  ('sweet', {74: 91, 'Number': 'plur'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('fry', {74: 99, 'Aspect': 'perf', 'Tense': 'past', 'VerbForm': 'part'}),\n",
       "  ('potato', {74: 91, 'Number': 'plur'})],\n",
       " [('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('do',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('not', {74: 85, 'Degree': 'pos'}),\n",
       "  ('even', {74: 85, 'Degree': 'pos'}),\n",
       "  ('eat', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('some', {74: 89}),\n",
       "  ('very', {74: 85, 'Degree': 'pos'}),\n",
       "  ('sweet', {74: 83, 'Degree': 'pos'}),\n",
       "  ('fruit', {74: 91, 'Number': 'sing'})],\n",
       " [('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('cook',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('vegetable', {74: 91, 'Number': 'plur'}),\n",
       "  ('fish', {74: 99, 'Tense': 'pres', 'VerbForm': 'fin'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('boil', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('meat', {74: 91, 'Number': 'sing'})],\n",
       " [('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('write',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('down', {74: 84}),\n",
       "  ('everything', {74: 91, 'Number': 'sing'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('eat',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('into', {74: 84}),\n",
       "  ('a', {74: 89}),\n",
       "  ('special', {74: 83, 'Degree': 'pos'}),\n",
       "  ('notebook', {74: 91, 'Number': 'sing'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('add',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('up', {74: 93}),\n",
       "  ('the', {74: 89}),\n",
       "  ('calorie', {74: 91, 'Number': 'plur'})],\n",
       " [('what', {74: 91, 'PronType': 'int|rel'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('more', {74: 85, 'Degree': 'comp'}),\n",
       "  ('every', {74: 89}),\n",
       "  ('morning', {74: 91, 'Number': 'sing'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('practice',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('jog', {74: 99, 'Aspect': 'prog', 'Tense': 'pres', 'VerbForm': 'part'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('go',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('to', {74: 84}),\n",
       "  ('the', {74: 89}),\n",
       "  ('gym', {74: 91, 'Number': 'sing'})],\n",
       " [('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('lose', {74: 99, 'Tense': 'past', 'VerbForm': 'fin'}),\n",
       "  ('three', {74: 92, 'NumType': 'card'}),\n",
       "  ('kilo', {74: 91, 'Number': 'plur'}),\n",
       "  ('but', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('want',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('to', {74: 93, 'PartType': 'inf', 'VerbForm': 'inf'}),\n",
       "  ('lose', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('two', {74: 92, 'NumType': 'card'}),\n",
       "  ('kilo', {74: 91, 'Number': 'plur'}),\n",
       "  ('more', {74: 83, 'Degree': 'comp'})],\n",
       " [('everyone', {74: 91, 'Number': 'sing'}),\n",
       "  ('tell',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('her', {74: 94, 'PronType': 'prs'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('look',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('great', {74: 83, 'Degree': 'pos'}),\n",
       "  ('but', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('do',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('not', {74: 85, 'Degree': 'pos'}),\n",
       "  ('agree', {74: 99, 'VerbForm': 'inf'})],\n",
       " [('she', {74: 94, 'PronType': 'prs'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('dream', {74: 99, 'Aspect': 'prog', 'Tense': 'pres', 'VerbForm': 'part'}),\n",
       "  ('about', {74: 84}),\n",
       "  ('a', {74: 89}),\n",
       "  ('slice', {74: 91, 'Number': 'sing'}),\n",
       "  ('of', {74: 84}),\n",
       "  ('wedding', {74: 91, 'Number': 'sing'}),\n",
       "  ('cake', {74: 91, 'Number': 'sing'}),\n",
       "  ('and', {74: 88, 'ConjType': 'coor'}),\n",
       "  ('do',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('not', {74: 85, 'Degree': 'pos'}),\n",
       "  ('want', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('to', {74: 93, 'PartType': 'inf', 'VerbForm': 'inf'}),\n",
       "  ('give', {74: 99, 'VerbForm': 'inf'}),\n",
       "  ('up', {74: 93})],\n",
       " [('dieting', {74: 91, 'Number': 'sing'}),\n",
       "  ('be',\n",
       "   {74: 99,\n",
       "    'Number': 'sing',\n",
       "    'Person': 3,\n",
       "    'Tense': 'pres',\n",
       "    'VerbForm': 'fin'}),\n",
       "  ('not', {74: 85, 'Degree': 'pos'}),\n",
       "  ('easy', {74: 83, 'Degree': 'pos'})]]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accompany': 0.323,\n",
       " 'add': 0.39,\n",
       " 'ago': 0.488,\n",
       " 'agree': 0.371,\n",
       " 'also': 0.323,\n",
       " 'apple': 0.341,\n",
       " 'ask': 0.514,\n",
       " 'banana': 0.341,\n",
       " 'beautiful': 0.415,\n",
       " 'boil': 0.447,\n",
       " 'breakfast': 0.341,\n",
       " 'bridesmaid': 0.514,\n",
       " 'brush': 0.298,\n",
       " 'bunch': 0.323,\n",
       " 'buy': 0.415,\n",
       " 'cake': 0.189,\n",
       " 'calorie': 0.39,\n",
       " 'carry': 0.323,\n",
       " 'ceremony': 0.371,\n",
       " 'church': 0.207,\n",
       " 'clothe': 0.232,\n",
       " 'confetti': 0.232,\n",
       " 'cook': 0.447,\n",
       " 'could': 0.5,\n",
       " 'day': 0.298,\n",
       " 'diet': 0.844,\n",
       " 'dieting': 0.707,\n",
       " 'dream': 0.441,\n",
       " 'dress': 0.266,\n",
       " 'easy': 0.707,\n",
       " 'eat': 0.176,\n",
       " 'even': 0.573,\n",
       " 'every': 0.408,\n",
       " 'everyone': 0.457,\n",
       " 'everything': 0.39,\n",
       " 'fish': 0.447,\n",
       " 'fit': 0.5,\n",
       " 'flower': 0.323,\n",
       " 'friend': 0.774,\n",
       " 'fruit': 0.512,\n",
       " 'fry': 0.505,\n",
       " 'get': 0.529,\n",
       " 'give': 0.441,\n",
       " 'glass': 0.341,\n",
       " 'go': 0.408,\n",
       " 'good': 0.341,\n",
       " 'great': 0.457,\n",
       " 'green': 0.378,\n",
       " 'guest': 0.232,\n",
       " 'gym': 0.408,\n",
       " 'hair': 0.298,\n",
       " 'hard': 0.598,\n",
       " 'help': 0.298,\n",
       " 'home': 0.5,\n",
       " 'husband': 0.232,\n",
       " 'india': 1.0,\n",
       " 'inside': 0.426,\n",
       " 'invitation': 0.774,\n",
       " 'jimmy': 0.439,\n",
       " 'jog': 0.408,\n",
       " 'juice': 0.341,\n",
       " 'juicy': 0.774,\n",
       " 'kilo': 0.62,\n",
       " 'last': 0.488,\n",
       " 'letter': 0.436,\n",
       " 'like': 0.537,\n",
       " 'long': 0.423,\n",
       " 'look': 0.457,\n",
       " 'lose': 0.62,\n",
       " 'lot': 0.232,\n",
       " 'lovely': 0.746,\n",
       " 'make': 0.232,\n",
       " 'marry': 0.529,\n",
       " 'mean': 0.298,\n",
       " 'meat': 0.447,\n",
       " 'meet': 0.232,\n",
       " 'month': 0.488,\n",
       " 'morning': 0.408,\n",
       " 'much': 0.537,\n",
       " 'must': 0.266,\n",
       " 'near': 0.232,\n",
       " 'nice': 0.207,\n",
       " 'notebook': 0.39,\n",
       " 'orange': 0.341,\n",
       " 'outside': 0.477,\n",
       " 'people': 0.232,\n",
       " 'photo': 0.232,\n",
       " 'pity': 1.0,\n",
       " 'place': 0.598,\n",
       " 'pleasure': 0.415,\n",
       " 'potato': 0.505,\n",
       " 'practice': 0.408,\n",
       " 'put': 0.298,\n",
       " 'receive': 0.488,\n",
       " 'red': 0.477,\n",
       " 'sally': 0.189,\n",
       " 'saturday': 0.598,\n",
       " 'see': 0.488,\n",
       " 'silk': 0.423,\n",
       " 'sister': 0.529,\n",
       " 'skirt': 0.423,\n",
       " 'slice': 0.441,\n",
       " 'soft': 0.598,\n",
       " 'special': 0.39,\n",
       " 'sweet': 0.413,\n",
       " 'take': 0.207,\n",
       " 'tasty': 0.232,\n",
       " 'tell': 0.457,\n",
       " 'three': 0.277,\n",
       " 'throw': 0.232,\n",
       " 'traditional': 0.323,\n",
       " 'two': 0.277,\n",
       " 'understand': 0.5,\n",
       " 'vegetable': 0.447,\n",
       " 'vegetarian': 0.774,\n",
       " 'victoria': 0.226,\n",
       " 'video': 0.232,\n",
       " 'want': 0.277,\n",
       " 'watermelon': 0.426,\n",
       " 'way': 0.323,\n",
       " 'wear': 0.232,\n",
       " 'wedding': 0.361,\n",
       " 'white': 0.423,\n",
       " 'wife': 0.232,\n",
       " 'write': 0.39,\n",
       " 'year': 0.488}"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_tf_idf(text_grammar_map, weights_list, debug = False):\n",
    "    for sentence_grammar_map, sentence_weights in zip(text_grammar_map,weights_list):\n",
    "        for el_ind in range(len(sentence_grammar_map)):\n",
    "            lemma = sentence_grammar_map[el_ind][0]\n",
    "            if(lemma in tf_idf_dict):\n",
    "                sentence_weights[el_ind][\"weight\"] = tf_idf_dict[lemma]\n",
    "            else:\n",
    "                sentence_weights[el_ind][\"weight\"] = 0.1\n",
    "    return weights_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrasal Verb found: agree with\n",
      "Phrasal Verb found: add up\n",
      "Phrasal Verb found: give up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'weight': 0.1, 'word': 'this'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.1, 'word': 'my'},\n",
       "  {'weight': 0.774, 'word': 'friend'},\n",
       "  {'weight': 0.439, 'word': 'jimmy'}],\n",
       " [{'weight': 0.1, 'word': 'he'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.1, 'word': 'from'},\n",
       "  {'weight': 1.0, 'word': 'india'}],\n",
       " [{'weight': 0.439, 'word': 'jimmy'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.774, 'word': 'vegetarian'}],\n",
       " [{'weight': 0.1, 'word': 'the'},\n",
       "  {'weight': 0.341, 'word': 'good'},\n",
       "  {'weight': 0.341, 'word': 'breakfast'},\n",
       "  {'weight': 0.1, 'word': 'for'},\n",
       "  {'weight': 0.1, 'word': 'him'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.341, 'word': 'glass'},\n",
       "  {'weight': 0.1, 'word': 'of'},\n",
       "  {'weight': 0.341, 'word': 'orange'},\n",
       "  {'weight': 0.341, 'word': 'juice'},\n",
       "  {'weight': 0.277, 'word': 'two'},\n",
       "  {'weight': 0.341, 'word': 'apple'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.277, 'word': 'three'},\n",
       "  {'weight': 0.341, 'word': 'banana'}],\n",
       " [{'weight': 0.439, 'word': 'jimmy'},\n",
       "  {'weight': 0.537, 'word': 'like'},\n",
       "  {'weight': 0.426, 'word': 'watermelon'},\n",
       "  {'weight': 0.1, 'word': 'very'},\n",
       "  {'weight': 0.537, 'word': 'much'}],\n",
       " [{'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.426, 'word': 'watermelon'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.378, 'word': 'green'},\n",
       "  {'weight': 0.477, 'word': 'outside'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.477, 'word': 'red'},\n",
       "  {'weight': 0.426, 'word': 'inside'}],\n",
       " [{'weight': 0.1, 'word': 'it'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.598, 'word': 'hard'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.598, 'word': 'soft'},\n",
       "  {'weight': 0.426, 'word': 'inside'}],\n",
       " [{'weight': 0.1, 'word': 'it'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.774, 'word': 'juicy'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.413, 'word': 'sweet'}],\n",
       " [{'weight': 0.1, 'word': 'what'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.746, 'word': 'lovely'},\n",
       "  {'weight': 0.512, 'word': 'fruit'}],\n",
       " [{'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.488, 'word': 'month'},\n",
       "  {'weight': 0.488, 'word': 'ago'},\n",
       "  {'weight': 0.189, 'word': 'sally'},\n",
       "  {'weight': 0.488, 'word': 'receive'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.436, 'word': 'letter'}],\n",
       " [{'weight': 0.1, 'word': 'it'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.1, 'word': 'an'},\n",
       "  {'weight': 0.774, 'word': 'invitation'},\n",
       "  {'weight': 0.1, 'word': 'for'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.361, 'word': 'wedding'}],\n",
       " [{'weight': 0.1, 'word': 'her'},\n",
       "  {'weight': 0.529, 'word': 'sister'},\n",
       "  {'weight': 0.226, 'word': 'victoria'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.529, 'word': 'get'},\n",
       "  {'weight': 0.529, 'word': 'marry'}],\n",
       " [{'weight': 0.488, 'word': 'last'},\n",
       "  {'weight': 0.488, 'word': 'year'},\n",
       "  {'weight': 0.189, 'word': 'sally'},\n",
       "  {'weight': 0.488, 'word': 'see'},\n",
       "  {'weight': 0.1, 'word': 'such'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.371, 'word': 'ceremony'}],\n",
       " [{'weight': 0.1, 'word': 'it'},\n",
       "  {'weight': 0.207, 'word': 'take'},\n",
       "  {'weight': 0.598, 'word': 'place'},\n",
       "  {'weight': 0.1, 'word': 'on'},\n",
       "  {'weight': 0.598, 'word': 'saturday'}],\n",
       " [{'weight': 0.1, 'word': 'there'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.232, 'word': 'lot'},\n",
       "  {'weight': 0.1, 'word': 'of'},\n",
       "  {'weight': 0.232, 'word': 'guest'},\n",
       "  {'weight': 0.232, 'word': 'people'},\n",
       "  {'weight': 0.232, 'word': 'wear'},\n",
       "  {'weight': 0.207, 'word': 'nice'},\n",
       "  {'weight': 0.232, 'word': 'clothe'},\n",
       "  {'weight': 0.232, 'word': 'meet'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.232, 'word': 'husband'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.232, 'word': 'wife'},\n",
       "  {'weight': 0.232, 'word': 'near'},\n",
       "  {'weight': 0.1, 'word': 'the'},\n",
       "  {'weight': 0.207, 'word': 'church'},\n",
       "  {'weight': 0.232, 'word': 'throw'},\n",
       "  {'weight': 0.232, 'word': 'confetti'},\n",
       "  {'weight': 0.176, 'word': 'eat'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.1, 'word': 'very'},\n",
       "  {'weight': 0.232, 'word': 'tasty'},\n",
       "  {'weight': 0.189, 'word': 'cake'},\n",
       "  {'weight': 0.232, 'word': 'make'},\n",
       "  {'weight': 0.232, 'word': 'video'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.207, 'word': 'take'},\n",
       "  {'weight': 0.232, 'word': 'photo'}],\n",
       " [{'weight': 0.1, 'word': 'in'},\n",
       "  {'weight': 0.1, 'word': 'her'},\n",
       "  {'weight': 0.436, 'word': 'letter'},\n",
       "  {'weight': 0.226, 'word': 'victoria'},\n",
       "  {'weight': 0.514, 'word': 'ask'},\n",
       "  {'weight': 0.189, 'word': 'sally'},\n",
       "  {'weight': 0.1, 'word': 'to'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.1, 'word': 'her'},\n",
       "  {'weight': 0.514, 'word': 'bridesmaid'}],\n",
       " [{'weight': 0.1, 'word': 'it'},\n",
       "  {'weight': 0.298, 'word': 'mean'},\n",
       "  {'weight': 0.1, 'word': 'that'},\n",
       "  {'weight': 0.1, 'word': 'on'},\n",
       "  {'weight': 0.1, 'word': 'the'},\n",
       "  {'weight': 0.298, 'word': 'day'},\n",
       "  {'weight': 0.1, 'word': 'of'},\n",
       "  {'weight': 0.361, 'word': 'wedding'},\n",
       "  {'weight': 0.189, 'word': 'sally'},\n",
       "  {'weight': 0.266, 'word': 'must'},\n",
       "  {'weight': 0.298, 'word': 'help'},\n",
       "  {'weight': 0.226, 'word': 'victoria'},\n",
       "  {'weight': 0.1, 'word': 'when'},\n",
       "  {'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.298, 'word': 'put'},\n",
       "  {'weight': 0.1, 'word': 'her'},\n",
       "  {'weight': 0.361, 'word': 'wedding'},\n",
       "  {'weight': 0.266, 'word': 'dress'},\n",
       "  {'weight': 0.1, 'word': 'on'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.298, 'word': 'brush'},\n",
       "  {'weight': 0.1, 'word': 'her'},\n",
       "  {'weight': 0.298, 'word': 'hair'}],\n",
       " [{'weight': 0.189, 'word': 'sally'},\n",
       "  {'weight': 0.266, 'word': 'must'},\n",
       "  {'weight': 0.323, 'word': 'also'},\n",
       "  {'weight': 0.323, 'word': 'accompany'},\n",
       "  {'weight': 0.226, 'word': 'victoria'},\n",
       "  {'weight': 0.1, 'word': 'on'},\n",
       "  {'weight': 0.1, 'word': 'her'},\n",
       "  {'weight': 0.323, 'word': 'way'},\n",
       "  {'weight': 0.1, 'word': 'to'},\n",
       "  {'weight': 0.1, 'word': 'the'},\n",
       "  {'weight': 0.207, 'word': 'church'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.323, 'word': 'carry'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.323, 'word': 'traditional'},\n",
       "  {'weight': 0.323, 'word': 'bunch'},\n",
       "  {'weight': 0.1, 'word': 'of'},\n",
       "  {'weight': 0.323, 'word': 'flower'}],\n",
       " [{'weight': 0.189, 'word': 'sally'},\n",
       "  {'phrasal_verb': 'yes', 'weight': 0.371, 'word': 'agree'},\n",
       "  {'phrasal_verb': 'yes', 'weight': 0.1, 'word': 'with'},\n",
       "  {'weight': 0.415, 'word': 'pleasure'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.415, 'word': 'buy'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.415, 'word': 'beautiful'},\n",
       "  {'weight': 0.266, 'word': 'dress'},\n",
       "  {'weight': 0.1, 'word': 'for'},\n",
       "  {'weight': 0.1, 'word': 'the'},\n",
       "  {'weight': 0.371, 'word': 'ceremony'}],\n",
       " [{'weight': 0.1, 'word': 'it'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.423, 'word': 'white'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.378, 'word': 'green'},\n",
       "  {'weight': 0.1, 'word': 'with'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.423, 'word': 'long'},\n",
       "  {'weight': 0.207, 'word': 'nice'},\n",
       "  {'weight': 0.423, 'word': 'silk'},\n",
       "  {'weight': 0.423, 'word': 'skirt'}],\n",
       " [{'weight': 0.1, 'word': 'but'},\n",
       "  {'weight': 0.1, 'word': 'at'},\n",
       "  {'weight': 0.5, 'word': 'home'},\n",
       "  {'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.5, 'word': 'understand'},\n",
       "  {'weight': 0.1, 'word': 'that'},\n",
       "  {'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.5, 'word': 'could'},\n",
       "  {'weight': 0.1, 'word': 'not'},\n",
       "  {'weight': 0.5, 'word': 'fit'},\n",
       "  {'weight': 0.1, 'word': 'into'},\n",
       "  {'weight': 0.1, 'word': 'it'}],\n",
       " [{'weight': 0.1, 'word': 'what'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 1.0, 'word': 'pity'}],\n",
       " [{'weight': 0.1, 'word': 'that'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.1, 'word': 'why'},\n",
       "  {'weight': 0.189, 'word': 'sally'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.1, 'word': 'on'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.844, 'word': 'diet'},\n",
       "  {'weight': 0.1, 'word': 'now'}],\n",
       " [{'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.1, 'word': 'do'},\n",
       "  {'weight': 0.1, 'word': 'not'},\n",
       "  {'weight': 0.176, 'word': 'eat'},\n",
       "  {'weight': 0.189, 'word': 'cake'},\n",
       "  {'weight': 0.413, 'word': 'sweet'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.505, 'word': 'fry'},\n",
       "  {'weight': 0.505, 'word': 'potato'}],\n",
       " [{'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.1, 'word': 'do'},\n",
       "  {'weight': 0.1, 'word': 'not'},\n",
       "  {'weight': 0.573, 'word': 'even'},\n",
       "  {'weight': 0.176, 'word': 'eat'},\n",
       "  {'weight': 0.1, 'word': 'some'},\n",
       "  {'weight': 0.1, 'word': 'very'},\n",
       "  {'weight': 0.413, 'word': 'sweet'},\n",
       "  {'weight': 0.512, 'word': 'fruit'}],\n",
       " [{'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.447, 'word': 'cook'},\n",
       "  {'weight': 0.447, 'word': 'vegetable'},\n",
       "  {'weight': 0.447, 'word': 'fish'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.447, 'word': 'boil'},\n",
       "  {'weight': 0.447, 'word': 'meat'}],\n",
       " [{'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.39, 'word': 'write'},\n",
       "  {'weight': 0.1, 'word': 'down'},\n",
       "  {'weight': 0.39, 'word': 'everything'},\n",
       "  {'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.176, 'word': 'eat'},\n",
       "  {'weight': 0.1, 'word': 'into'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.39, 'word': 'special'},\n",
       "  {'weight': 0.39, 'word': 'notebook'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'phrasal_verb': 'yes', 'weight': 0.39, 'word': 'add'},\n",
       "  {'phrasal_verb': 'yes', 'weight': 0.1, 'word': 'up'},\n",
       "  {'weight': 0.1, 'word': 'the'},\n",
       "  {'weight': 0.39, 'word': 'calorie'}],\n",
       " [{'weight': 0.1, 'word': 'what'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.1, 'word': 'more'},\n",
       "  {'weight': 0.408, 'word': 'every'},\n",
       "  {'weight': 0.408, 'word': 'morning'},\n",
       "  {'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.408, 'word': 'practice'},\n",
       "  {'weight': 0.408, 'word': 'jog'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.408, 'word': 'go'},\n",
       "  {'weight': 0.1, 'word': 'to'},\n",
       "  {'weight': 0.1, 'word': 'the'},\n",
       "  {'weight': 0.408, 'word': 'gym'}],\n",
       " [{'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.62, 'word': 'lose'},\n",
       "  {'weight': 0.277, 'word': 'three'},\n",
       "  {'weight': 0.62, 'word': 'kilo'},\n",
       "  {'weight': 0.1, 'word': 'but'},\n",
       "  {'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.277, 'word': 'want'},\n",
       "  {'weight': 0.1, 'word': 'to'},\n",
       "  {'weight': 0.62, 'word': 'lose'},\n",
       "  {'weight': 0.277, 'word': 'two'},\n",
       "  {'weight': 0.62, 'word': 'kilo'},\n",
       "  {'weight': 0.1, 'word': 'more'}],\n",
       " [{'weight': 0.457, 'word': 'everyone'},\n",
       "  {'weight': 0.457, 'word': 'tell'},\n",
       "  {'weight': 0.1, 'word': 'her'},\n",
       "  {'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.457, 'word': 'look'},\n",
       "  {'weight': 0.457, 'word': 'great'},\n",
       "  {'weight': 0.1, 'word': 'but'},\n",
       "  {'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.1, 'word': 'do'},\n",
       "  {'weight': 0.1, 'word': 'not'},\n",
       "  {'weight': 0.371, 'word': 'agree'}],\n",
       " [{'weight': 0.1, 'word': 'she'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.441, 'word': 'dream'},\n",
       "  {'weight': 0.1, 'word': 'about'},\n",
       "  {'weight': 0.1, 'word': 'a'},\n",
       "  {'weight': 0.441, 'word': 'slice'},\n",
       "  {'weight': 0.1, 'word': 'of'},\n",
       "  {'weight': 0.361, 'word': 'wedding'},\n",
       "  {'weight': 0.189, 'word': 'cake'},\n",
       "  {'weight': 0.1, 'word': 'and'},\n",
       "  {'weight': 0.1, 'word': 'do'},\n",
       "  {'weight': 0.1, 'word': 'not'},\n",
       "  {'weight': 0.277, 'word': 'want'},\n",
       "  {'weight': 0.1, 'word': 'to'},\n",
       "  {'phrasal_verb': 'yes', 'weight': 0.441, 'word': 'give'},\n",
       "  {'phrasal_verb': 'yes', 'weight': 0.1, 'word': 'up'}],\n",
       " [{'weight': 0.707, 'word': 'dieting'},\n",
       "  {'weight': 0.1, 'word': 'be'},\n",
       "  {'weight': 0.1, 'word': 'not'},\n",
       "  {'weight': 0.707, 'word': 'easy'}]]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_text_weights = get_weights_empty_list(grammar_map)\n",
    "ex_text_weights = get_difficult_grammar(grammar_map, ex_text_weights, debug = True)\n",
    "ex_text_weights = get_phrasal_verbs(grammar_map, ex_text_weights, debug = True)\n",
    "ex_text_weights = assign_tf_idf(grammar_map, ex_text_weights, debug = True)\n",
    "ex_text_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_groups(text_weights):\n",
    "    difficult_vocabulary = []\n",
    "    easy_vocabulary = []\n",
    "    for sentence_weights in text_weights:\n",
    "        for word_weight in sentence_weights:\n",
    "            #print(word_weight)\n",
    "            if('diff_grammar' in word_weight or 'phrasal_verb' in word_weight or word_weight['word'] not in basic_vocabulary):\n",
    "                difficult_vocabulary.append(word_weight)\n",
    "            \n",
    "            else:\n",
    "                easy_vocabulary.append(word_weight)\n",
    "    return easy_vocabulary, difficult_vocabulary\n",
    "                \n",
    "easy, difficult = split_into_groups(ex_text_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'weight': 0.774, 'word': 'vegetarian'},\n",
       " {'weight': 0.426, 'word': 'watermelon'},\n",
       " {'weight': 0.426, 'word': 'watermelon'},\n",
       " {'weight': 0.598, 'word': 'soft'},\n",
       " {'weight': 0.774, 'word': 'juicy'},\n",
       " {'weight': 0.746, 'word': 'lovely'},\n",
       " {'weight': 0.488, 'word': 'receive'},\n",
       " {'weight': 0.774, 'word': 'invitation'},\n",
       " {'weight': 0.361, 'word': 'wedding'},\n",
       " {'weight': 0.529, 'word': 'marry'},\n",
       " {'weight': 0.1, 'word': 'such'},\n",
       " {'weight': 0.371, 'word': 'ceremony'},\n",
       " {'weight': 0.232, 'word': 'guest'},\n",
       " {'weight': 0.232, 'word': 'clothe'},\n",
       " {'weight': 0.207, 'word': 'church'},\n",
       " {'weight': 0.232, 'word': 'throw'},\n",
       " {'weight': 0.232, 'word': 'confetti'},\n",
       " {'weight': 0.232, 'word': 'tasty'},\n",
       " {'weight': 0.232, 'word': 'video'},\n",
       " {'weight': 0.514, 'word': 'bridesmaid'},\n",
       " {'weight': 0.298, 'word': 'mean'},\n",
       " {'weight': 0.361, 'word': 'wedding'},\n",
       " {'weight': 0.266, 'word': 'must'},\n",
       " {'weight': 0.361, 'word': 'wedding'},\n",
       " {'weight': 0.298, 'word': 'brush'},\n",
       " {'weight': 0.266, 'word': 'must'},\n",
       " {'weight': 0.323, 'word': 'accompany'},\n",
       " {'weight': 0.323, 'word': 'way'},\n",
       " {'weight': 0.207, 'word': 'church'},\n",
       " {'weight': 0.323, 'word': 'traditional'},\n",
       " {'weight': 0.323, 'word': 'bunch'},\n",
       " {'phrasal_verb': 'yes', 'weight': 0.371, 'word': 'agree'},\n",
       " {'phrasal_verb': 'yes', 'weight': 0.1, 'word': 'with'},\n",
       " {'weight': 0.415, 'word': 'pleasure'},\n",
       " {'weight': 0.371, 'word': 'ceremony'},\n",
       " {'weight': 0.423, 'word': 'silk'},\n",
       " {'weight': 0.5, 'word': 'fit'},\n",
       " {'weight': 1.0, 'word': 'pity'},\n",
       " {'weight': 0.844, 'word': 'diet'},\n",
       " {'weight': 0.505, 'word': 'fry'},\n",
       " {'weight': 0.573, 'word': 'even'},\n",
       " {'weight': 0.447, 'word': 'boil'},\n",
       " {'weight': 0.39, 'word': 'everything'},\n",
       " {'weight': 0.39, 'word': 'notebook'},\n",
       " {'phrasal_verb': 'yes', 'weight': 0.39, 'word': 'add'},\n",
       " {'phrasal_verb': 'yes', 'weight': 0.1, 'word': 'up'},\n",
       " {'weight': 0.39, 'word': 'calorie'},\n",
       " {'weight': 0.408, 'word': 'practice'},\n",
       " {'weight': 0.408, 'word': 'jog'},\n",
       " {'weight': 0.408, 'word': 'gym'},\n",
       " {'weight': 0.62, 'word': 'lose'},\n",
       " {'weight': 0.62, 'word': 'kilo'},\n",
       " {'weight': 0.62, 'word': 'lose'},\n",
       " {'weight': 0.62, 'word': 'kilo'},\n",
       " {'weight': 0.457, 'word': 'everyone'},\n",
       " {'weight': 0.371, 'word': 'agree'},\n",
       " {'weight': 0.441, 'word': 'dream'},\n",
       " {'weight': 0.441, 'word': 'slice'},\n",
       " {'weight': 0.361, 'word': 'wedding'},\n",
       " {'phrasal_verb': 'yes', 'weight': 0.441, 'word': 'give'},\n",
       " {'phrasal_verb': 'yes', 'weight': 0.1, 'word': 'up'},\n",
       " {'weight': 0.707, 'word': 'dieting'}]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difficult"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
